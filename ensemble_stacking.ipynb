{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"font-family:Times New Roman;\">Kaggle Competition</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-family:Times New Roman;\"><b><font size = \"4\">Suhas Alur</font></b></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"font-family:Times New Roman;\">Loading & Pre-processing</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Suhas\\Documents\\MSBA\\Semester Two\\Predictive Analytics\\Homework\\Homework - 5\\Data\n"
     ]
    }
   ],
   "source": [
    "# import necessary libraries and specify that graphs should be plotted inline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import svm, datasets\n",
    "%cd 'C:\\Users\\Suhas\\Documents\\MSBA\\Semester Two\\Predictive Analytics\\Homework\\Homework - 5\\Data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import the train dataset\n",
    "data_train = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Splitting the dataset based on attributes and target variable\n",
    "X = data_train.iloc[:,0:25]\n",
    "y = data_train.adopter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = np.array(X)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Splitting the train data into training and testing\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X, X_submission, y, y_suhas = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import the train dataset\n",
    "#data_test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Taking only the required attributes\n",
    "#X_submission = data_test.iloc[:,0:25]\n",
    "#X_submission = np.array(X_submission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import numpy as np\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def logloss(attempt, actual, epsilon=1.0e-15):\n",
    "    \"\"\"Logloss, i.e. the score of the bioresponse competition.\n",
    "    \"\"\"\n",
    "    attempt = np.clip(attempt, epsilon, 1.0-epsilon)\n",
    "    return - np.mean(actual * np.log(attempt) +\n",
    "                     (1.0 - actual) * np.log(1.0 - attempt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(0)  # seed to shuffle the train set\n",
    "n_folds = 10\n",
    "verbose = True\n",
    "shuffle = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if shuffle:\n",
    "    idx = np.random.permutation(y.size)\n",
    "    X = X[idx]\n",
    "    y = y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "skf = list(StratifiedKFold(y, n_folds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clfs = [RandomForestClassifier(n_estimators = 100, max_depth = 10, max_features = 7, min_samples_split = 4, bootstrap = True, oob_score = True, n_jobs = -1, class_weight = 'balanced', random_state = 42, criterion='gini'),\n",
    "        RandomForestClassifier(n_estimators = 100, max_depth = 10, max_features = 7, min_samples_split = 4, bootstrap = True, oob_score = True, n_jobs = -1, class_weight = 'balanced', random_state = 42, criterion='entropy'),\n",
    "        GradientBoostingClassifier(loss = 'deviance', learning_rate=0.05, min_weight_fraction_leaf = 0.1, min_samples_split=2, n_estimators=80, max_depth=20, subsample=0.1,random_state=42),\n",
    "        GradientBoostingClassifier(loss = 'exponential', learning_rate=0.05, min_weight_fraction_leaf = 0.1, min_samples_split=2, n_estimators=80, max_depth=20, subsample=0.1,random_state=42),\n",
    "        ExtraTreesClassifier(n_estimators=100, n_jobs=-1, criterion='gini',random_state=42),\n",
    "        ExtraTreesClassifier(n_estimators=100, n_jobs=-1, criterion='entropy',random_state=42),\n",
    "        xgb.XGBClassifier(learning_rate =0.8, n_estimators=100, max_depth=2, min_child_weight=6, gamma=5, subsample=1, colsample_bytree=0.5, reg_alpha=0.1, objective= 'binary:logistic', nthread=10, scale_pos_weight=1, seed=42),\n",
    "        xgb.XGBClassifier(learning_rate =0.1, n_estimators=100, max_depth=2, min_child_weight=6, gamma=5, subsample=1, colsample_bytree=0.1, reg_alpha=0.01, objective= 'binary:logistic', nthread=20, scale_pos_weight=1, seed=42)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating train and test sets for blending.\n",
      "0 RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
      "            criterion='gini', max_depth=10, max_features=7,\n",
      "            max_leaf_nodes=None, min_impurity_split=1e-07,\n",
      "            min_samples_leaf=1, min_samples_split=4,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
      "            oob_score=True, random_state=42, verbose=0, warm_start=False)\n",
      "Fold 0\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "Fold 5\n",
      "Fold 6\n",
      "Fold 7\n",
      "Fold 8\n",
      "Fold 9\n",
      "1 RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
      "            criterion='entropy', max_depth=10, max_features=7,\n",
      "            max_leaf_nodes=None, min_impurity_split=1e-07,\n",
      "            min_samples_leaf=1, min_samples_split=4,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
      "            oob_score=True, random_state=42, verbose=0, warm_start=False)\n",
      "Fold 0\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "Fold 5\n",
      "Fold 6\n",
      "Fold 7\n",
      "Fold 8\n",
      "Fold 9\n",
      "2 GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.05, loss='deviance', max_depth=20,\n",
      "              max_features=None, max_leaf_nodes=None,\n",
      "              min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "              min_samples_split=2, min_weight_fraction_leaf=0.1,\n",
      "              n_estimators=80, presort='auto', random_state=42,\n",
      "              subsample=0.1, verbose=0, warm_start=False)\n",
      "Fold 0\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "Fold 5\n",
      "Fold 6\n",
      "Fold 7\n",
      "Fold 8\n",
      "Fold 9\n",
      "3 GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.05, loss='exponential', max_depth=20,\n",
      "              max_features=None, max_leaf_nodes=None,\n",
      "              min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "              min_samples_split=2, min_weight_fraction_leaf=0.1,\n",
      "              n_estimators=80, presort='auto', random_state=42,\n",
      "              subsample=0.1, verbose=0, warm_start=False)\n",
      "Fold 0\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "Fold 5\n",
      "Fold 6\n",
      "Fold 7\n",
      "Fold 8\n",
      "Fold 9\n",
      "4 ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
      "           max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "           min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "           n_estimators=100, n_jobs=-1, oob_score=False, random_state=42,\n",
      "           verbose=0, warm_start=False)\n",
      "Fold 0\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "Fold 5\n",
      "Fold 6\n",
      "Fold 7\n",
      "Fold 8\n",
      "Fold 9\n",
      "5 ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='entropy',\n",
      "           max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "           min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "           n_estimators=100, n_jobs=-1, oob_score=False, random_state=42,\n",
      "           verbose=0, warm_start=False)\n",
      "Fold 0\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "Fold 5\n",
      "Fold 6\n",
      "Fold 7\n",
      "Fold 8\n",
      "Fold 9\n",
      "6 XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=0.5,\n",
      "       gamma=5, learning_rate=0.8, max_delta_step=0, max_depth=2,\n",
      "       min_child_weight=6, missing=None, n_estimators=100, nthread=10,\n",
      "       objective='binary:logistic', reg_alpha=0.1, reg_lambda=1,\n",
      "       scale_pos_weight=1, seed=42, silent=True, subsample=1)\n",
      "Fold 0\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "Fold 5\n",
      "Fold 6\n",
      "Fold 7\n",
      "Fold 8\n",
      "Fold 9\n",
      "7 XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=0.1,\n",
      "       gamma=5, learning_rate=0.1, max_delta_step=0, max_depth=2,\n",
      "       min_child_weight=6, missing=None, n_estimators=100, nthread=20,\n",
      "       objective='binary:logistic', reg_alpha=0.01, reg_lambda=1,\n",
      "       scale_pos_weight=1, seed=42, silent=True, subsample=1)\n",
      "Fold 0\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "Fold 5\n",
      "Fold 6\n",
      "Fold 7\n",
      "Fold 8\n",
      "Fold 9\n"
     ]
    }
   ],
   "source": [
    "print \"Creating train and test sets for blending.\"\n",
    "\n",
    "dataset_blend_train = np.zeros((X.shape[0], len(clfs)))\n",
    "dataset_blend_test = np.zeros((X_submission.shape[0], len(clfs)))\n",
    "\n",
    "for j, clf in enumerate(clfs):\n",
    "    print j, clf\n",
    "    dataset_blend_test_j = np.zeros((X_submission.shape[0], len(skf)))\n",
    "    for i, (train, test) in enumerate(skf):\n",
    "        print \"Fold\", i\n",
    "        X_train = X[train]\n",
    "        y_train = y[train]\n",
    "        X_test = X[test]\n",
    "        y_test = y[test]\n",
    "        clf.fit(X_train, y_train)\n",
    "        y_submission = clf.predict_proba(X_test)[:, 1]\n",
    "        dataset_blend_train[test, j] = y_submission\n",
    "        dataset_blend_test_j[:, i] = clf.predict_proba(X_submission)[:, 1]\n",
    "    dataset_blend_test[:, j] = dataset_blend_test_j.mean(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Blending...\n"
     ]
    }
   ],
   "source": [
    "print\n",
    "print \"Blending...\"\n",
    "clf = LogisticRegression(random_state = 9, C = 0.3, n_jobs = -1, penalty = 'l1', class_weight = 'balanced', intercept_scaling  = 1, multi_class = 'ovr', fit_intercept = False)\n",
    "clf.fit(dataset_blend_train, y)\n",
    "y_submission = clf.predict_proba(dataset_blend_test)[:, 1]\n",
    "\n",
    "# \n",
    "#print \"Linear stretch of predictions to [0,1]\"\n",
    "#y_submission = (y_submission - y_submission.min()) / (y_submission.max() - y_submission.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.47909544421871447"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_submission[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cutoff = 0.0\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.00      0.00      0.00     25566\n",
      "    class 1       0.02      1.00      0.03       439\n",
      "\n",
      "avg / total       0.00      0.02      0.00     26005\n",
      "\n",
      "[[    0 25566]\n",
      " [    0   439]]\n",
      "*********************************************************\n",
      "Cutoff = 0.01\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.00      0.00      0.00     25566\n",
      "    class 1       0.02      1.00      0.03       439\n",
      "\n",
      "avg / total       0.00      0.02      0.00     26005\n",
      "\n",
      "[[    0 25566]\n",
      " [    0   439]]\n",
      "*********************************************************\n",
      "Cutoff = 0.02\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.00      0.00      0.00     25566\n",
      "    class 1       0.02      1.00      0.03       439\n",
      "\n",
      "avg / total       0.00      0.02      0.00     26005\n",
      "\n",
      "[[    0 25566]\n",
      " [    0   439]]\n",
      "*********************************************************\n",
      "Cutoff = 0.03\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.00      0.00      0.00     25566\n",
      "    class 1       0.02      1.00      0.03       439\n",
      "\n",
      "avg / total       0.00      0.02      0.00     26005\n",
      "\n",
      "[[    0 25566]\n",
      " [    0   439]]\n",
      "*********************************************************\n",
      "Cutoff = 0.04\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.00      0.00      0.00     25566\n",
      "    class 1       0.02      1.00      0.03       439\n",
      "\n",
      "avg / total       0.00      0.02      0.00     26005\n",
      "\n",
      "[[    0 25566]\n",
      " [    0   439]]\n",
      "*********************************************************\n",
      "Cutoff = 0.05\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.00      0.00      0.00     25566\n",
      "    class 1       0.02      1.00      0.03       439\n",
      "\n",
      "avg / total       0.00      0.02      0.00     26005\n",
      "\n",
      "[[    0 25566]\n",
      " [    0   439]]\n",
      "*********************************************************\n",
      "Cutoff = 0.06\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.00      0.00      0.00     25566\n",
      "    class 1       0.02      1.00      0.03       439\n",
      "\n",
      "avg / total       0.00      0.02      0.00     26005\n",
      "\n",
      "[[    0 25566]\n",
      " [    0   439]]\n",
      "*********************************************************\n",
      "Cutoff = 0.07\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.00      0.00      0.00     25566\n",
      "    class 1       0.02      1.00      0.03       439\n",
      "\n",
      "avg / total       0.00      0.02      0.00     26005\n",
      "\n",
      "[[    0 25566]\n",
      " [    0   439]]\n",
      "*********************************************************\n",
      "Cutoff = 0.08\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.00      0.00      0.00     25566\n",
      "    class 1       0.02      1.00      0.03       439\n",
      "\n",
      "avg / total       0.00      0.02      0.00     26005\n",
      "\n",
      "[[    0 25566]\n",
      " [    0   439]]\n",
      "*********************************************************\n",
      "Cutoff = 0.09\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.00      0.00      0.00     25566\n",
      "    class 1       0.02      1.00      0.03       439\n",
      "\n",
      "avg / total       0.00      0.02      0.00     26005\n",
      "\n",
      "[[    0 25566]\n",
      " [    0   439]]\n",
      "*********************************************************\n",
      "Cutoff = 0.1\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.00      0.00      0.00     25566\n",
      "    class 1       0.02      1.00      0.03       439\n",
      "\n",
      "avg / total       0.00      0.02      0.00     26005\n",
      "\n",
      "[[    0 25566]\n",
      " [    0   439]]\n",
      "*********************************************************\n",
      "Cutoff = 0.11\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.00      0.00      0.00     25566\n",
      "    class 1       0.02      1.00      0.03       439\n",
      "\n",
      "avg / total       0.00      0.02      0.00     26005\n",
      "\n",
      "[[    0 25566]\n",
      " [    0   439]]\n",
      "*********************************************************\n",
      "Cutoff = 0.12\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.00      0.00      0.00     25566\n",
      "    class 1       0.02      1.00      0.03       439\n",
      "\n",
      "avg / total       0.00      0.02      0.00     26005\n",
      "\n",
      "[[    0 25566]\n",
      " [    0   439]]\n",
      "*********************************************************\n",
      "Cutoff = 0.13\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.00      0.00      0.00     25566\n",
      "    class 1       0.02      1.00      0.03       439\n",
      "\n",
      "avg / total       0.00      0.02      0.00     26005\n",
      "\n",
      "[[    0 25566]\n",
      " [    0   439]]\n",
      "*********************************************************\n",
      "Cutoff = 0.14\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.00      0.00      0.00     25566\n",
      "    class 1       0.02      1.00      0.03       439\n",
      "\n",
      "avg / total       0.00      0.02      0.00     26005\n",
      "\n",
      "[[    0 25566]\n",
      " [    0   439]]\n",
      "*********************************************************\n",
      "Cutoff = 0.15\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.00      0.00      0.00     25566\n",
      "    class 1       0.02      1.00      0.03       439\n",
      "\n",
      "avg / total       0.00      0.02      0.00     26005\n",
      "\n",
      "[[    0 25566]\n",
      " [    0   439]]\n",
      "*********************************************************\n",
      "Cutoff = 0.16\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.00      0.00      0.00     25566\n",
      "    class 1       0.02      1.00      0.03       439\n",
      "\n",
      "avg / total       0.00      0.02      0.00     26005\n",
      "\n",
      "[[    0 25566]\n",
      " [    0   439]]\n",
      "*********************************************************\n",
      "Cutoff = 0.17\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.00      0.00      0.00     25566\n",
      "    class 1       0.02      1.00      0.03       439\n",
      "\n",
      "avg / total       0.00      0.02      0.00     26005\n",
      "\n",
      "[[    0 25566]\n",
      " [    0   439]]\n",
      "*********************************************************\n",
      "Cutoff = 0.18\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.00      0.00      0.00     25566\n",
      "    class 1       0.02      1.00      0.03       439\n",
      "\n",
      "avg / total       0.00      0.02      0.00     26005\n",
      "\n",
      "[[    0 25566]\n",
      " [    0   439]]\n",
      "*********************************************************\n",
      "Cutoff = 0.19\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.00      0.00      0.00     25566\n",
      "    class 1       0.02      1.00      0.03       439\n",
      "\n",
      "avg / total       0.00      0.02      0.00     26005\n",
      "\n",
      "[[    0 25566]\n",
      " [    0   439]]\n",
      "*********************************************************\n",
      "Cutoff = 0.2\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.00      0.00      0.00     25566\n",
      "    class 1       0.02      1.00      0.03       439\n",
      "\n",
      "avg / total       0.00      0.02      0.00     26005\n",
      "\n",
      "[[    0 25566]\n",
      " [    0   439]]\n",
      "*********************************************************\n",
      "Cutoff = 0.21\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.00      0.00      0.00     25566\n",
      "    class 1       0.02      1.00      0.03       439\n",
      "\n",
      "avg / total       0.00      0.02      0.00     26005\n",
      "\n",
      "[[    0 25566]\n",
      " [    0   439]]\n",
      "*********************************************************\n",
      "Cutoff = 0.22\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.00      0.00      0.00     25566\n",
      "    class 1       0.02      1.00      0.03       439\n",
      "\n",
      "avg / total       0.00      0.02      0.00     26005\n",
      "\n",
      "[[    0 25566]\n",
      " [    0   439]]\n",
      "*********************************************************\n",
      "Cutoff = 0.23\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.00      0.00      0.00     25566\n",
      "    class 1       0.02      1.00      0.03       439\n",
      "\n",
      "avg / total       0.00      0.02      0.00     26005\n",
      "\n",
      "[[    0 25566]\n",
      " [    0   439]]\n",
      "*********************************************************\n",
      "Cutoff = 0.24\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.00      0.00      0.00     25566\n",
      "    class 1       0.02      1.00      0.03       439\n",
      "\n",
      "avg / total       0.00      0.02      0.00     26005\n",
      "\n",
      "[[    0 25566]\n",
      " [    0   439]]\n",
      "*********************************************************\n",
      "Cutoff = 0.25\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.00      0.00      0.00     25566\n",
      "    class 1       0.02      1.00      0.03       439\n",
      "\n",
      "avg / total       0.00      0.02      0.00     26005\n",
      "\n",
      "[[    0 25566]\n",
      " [    0   439]]\n",
      "*********************************************************\n",
      "Cutoff = 0.26\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.00      0.00      0.00     25566\n",
      "    class 1       0.02      1.00      0.03       439\n",
      "\n",
      "avg / total       0.00      0.02      0.00     26005\n",
      "\n",
      "[[    0 25566]\n",
      " [    0   439]]\n",
      "*********************************************************\n",
      "Cutoff = 0.27\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.00      0.00      0.00     25566\n",
      "    class 1       0.02      1.00      0.03       439\n",
      "\n",
      "avg / total       0.00      0.02      0.00     26005\n",
      "\n",
      "[[    0 25566]\n",
      " [    0   439]]\n",
      "*********************************************************\n",
      "Cutoff = 0.28\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.00      0.00      0.00     25566\n",
      "    class 1       0.02      1.00      0.03       439\n",
      "\n",
      "avg / total       0.00      0.02      0.00     26005\n",
      "\n",
      "[[    0 25566]\n",
      " [    0   439]]\n",
      "*********************************************************\n",
      "Cutoff = 0.29\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.00      0.00      0.00     25566\n",
      "    class 1       0.02      1.00      0.03       439\n",
      "\n",
      "avg / total       0.00      0.02      0.00     26005\n",
      "\n",
      "[[    0 25566]\n",
      " [    0   439]]\n",
      "*********************************************************\n",
      "Cutoff = 0.3\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.00      0.00      0.00     25566\n",
      "    class 1       0.02      1.00      0.03       439\n",
      "\n",
      "avg / total       0.00      0.02      0.00     26005\n",
      "\n",
      "[[    0 25566]\n",
      " [    0   439]]\n",
      "*********************************************************\n",
      "Cutoff = 0.31\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.00      0.00      0.00     25566\n",
      "    class 1       0.02      1.00      0.03       439\n",
      "\n",
      "avg / total       0.00      0.02      0.00     26005\n",
      "\n",
      "[[    0 25566]\n",
      " [    0   439]]\n",
      "*********************************************************\n",
      "Cutoff = 0.32\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.00      0.00      0.00     25566\n",
      "    class 1       0.02      1.00      0.03       439\n",
      "\n",
      "avg / total       0.00      0.02      0.00     26005\n",
      "\n",
      "[[    0 25566]\n",
      " [    0   439]]\n",
      "*********************************************************\n",
      "Cutoff = 0.33\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.00      0.00      0.00     25566\n",
      "    class 1       0.02      1.00      0.03       439\n",
      "\n",
      "avg / total       0.00      0.02      0.00     26005\n",
      "\n",
      "[[    0 25566]\n",
      " [    0   439]]\n",
      "*********************************************************\n",
      "Cutoff = 0.34\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.00      0.00      0.00     25566\n",
      "    class 1       0.02      1.00      0.03       439\n",
      "\n",
      "avg / total       0.00      0.02      0.00     26005\n",
      "\n",
      "[[    0 25566]\n",
      " [    0   439]]\n",
      "*********************************************************\n",
      "Cutoff = 0.35\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.00      0.00      0.00     25566\n",
      "    class 1       0.02      1.00      0.03       439\n",
      "\n",
      "avg / total       0.00      0.02      0.00     26005\n",
      "\n",
      "[[    0 25566]\n",
      " [    0   439]]\n",
      "*********************************************************\n",
      "Cutoff = 0.36\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       1.00      0.00      0.00     25566\n",
      "    class 1       0.02      1.00      0.03       439\n",
      "\n",
      "avg / total       0.98      0.02      0.00     26005\n",
      "\n",
      "[[    1 25565]\n",
      " [    0   439]]\n",
      "*********************************************************\n",
      "Cutoff = 0.37\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       1.00      0.00      0.00     25566\n",
      "    class 1       0.02      1.00      0.03       439\n",
      "\n",
      "avg / total       0.98      0.02      0.00     26005\n",
      "\n",
      "[[    1 25565]\n",
      " [    0   439]]\n",
      "*********************************************************\n",
      "Cutoff = 0.38\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       1.00      0.00      0.00     25566\n",
      "    class 1       0.02      1.00      0.03       439\n",
      "\n",
      "avg / total       0.98      0.02      0.00     26005\n",
      "\n",
      "[[    1 25565]\n",
      " [    0   439]]\n",
      "*********************************************************\n",
      "Cutoff = 0.39\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       1.00      0.00      0.00     25566\n",
      "    class 1       0.02      1.00      0.03       439\n",
      "\n",
      "avg / total       0.98      0.02      0.00     26005\n",
      "\n",
      "[[    1 25565]\n",
      " [    0   439]]\n",
      "*********************************************************\n",
      "Cutoff = 0.4\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       1.00      0.00      0.00     25566\n",
      "    class 1       0.02      1.00      0.03       439\n",
      "\n",
      "avg / total       0.98      0.02      0.00     26005\n",
      "\n",
      "[[    3 25563]\n",
      " [    0   439]]\n",
      "*********************************************************\n",
      "Cutoff = 0.41\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.80      0.00      0.00     25566\n",
      "    class 1       0.02      1.00      0.03       439\n",
      "\n",
      "avg / total       0.79      0.02      0.00     26005\n",
      "\n",
      "[[    8 25558]\n",
      " [    2   437]]\n",
      "*********************************************************\n",
      "Cutoff = 0.42\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.93      0.00      0.00     25566\n",
      "    class 1       0.02      1.00      0.03       439\n",
      "\n",
      "avg / total       0.92      0.02      0.00     26005\n",
      "\n",
      "[[   27 25539]\n",
      " [    2   437]]\n",
      "*********************************************************\n",
      "Cutoff = 0.43\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.98      0.00      0.01     25566\n",
      "    class 1       0.02      1.00      0.03       439\n",
      "\n",
      "avg / total       0.96      0.02      0.01     26005\n",
      "\n",
      "[[   93 25473]\n",
      " [    2   437]]\n",
      "*********************************************************\n",
      "Cutoff = 0.44\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.99      0.01      0.02     25566\n",
      "    class 1       0.02      0.99      0.03       439\n",
      "\n",
      "avg / total       0.97      0.03      0.02     26005\n",
      "\n",
      "[[  242 25324]\n",
      " [    3   436]]\n",
      "*********************************************************\n",
      "Cutoff = 0.45\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.99      0.03      0.05     25566\n",
      "    class 1       0.02      0.98      0.03       439\n",
      "\n",
      "avg / total       0.97      0.04      0.05     26005\n",
      "\n",
      "[[  669 24897]\n",
      " [    7   432]]\n",
      "*********************************************************\n",
      "Cutoff = 0.46\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.99      0.07      0.14     25566\n",
      "    class 1       0.02      0.97      0.03       439\n",
      "\n",
      "avg / total       0.98      0.09      0.14     26005\n",
      "\n",
      "[[ 1907 23659]\n",
      " [   12   427]]\n",
      "*********************************************************\n",
      "Cutoff = 0.47\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.99      0.18      0.31     25566\n",
      "    class 1       0.02      0.92      0.04       439\n",
      "\n",
      "avg / total       0.98      0.19      0.30     26005\n",
      "\n",
      "[[ 4636 20930]\n",
      " [   34   405]]\n",
      "*********************************************************\n",
      "Cutoff = 0.48\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.99      0.34      0.51     25566\n",
      "    class 1       0.02      0.89      0.04       439\n",
      "\n",
      "avg / total       0.98      0.35      0.50     26005\n",
      "\n",
      "[[ 8773 16793]\n",
      " [   47   392]]\n",
      "*********************************************************\n",
      "Cutoff = 0.49\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.99      0.54      0.70     25566\n",
      "    class 1       0.03      0.84      0.06       439\n",
      "\n",
      "avg / total       0.98      0.54      0.69     26005\n",
      "\n",
      "[[13697 11869]\n",
      " [   71   368]]\n",
      "*********************************************************\n",
      "Cutoff = 0.5\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.99      0.60      0.75     25566\n",
      "    class 1       0.03      0.82      0.07       439\n",
      "\n",
      "avg / total       0.98      0.60      0.74     26005\n",
      "\n",
      "[[15357 10209]\n",
      " [   80   359]]\n",
      "*********************************************************\n",
      "Cutoff = 0.51\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.99      0.64      0.78     25566\n",
      "    class 1       0.04      0.78      0.07       439\n",
      "\n",
      "avg / total       0.98      0.64      0.77     26005\n",
      "\n",
      "[[16392  9174]\n",
      " [   95   344]]\n",
      "*********************************************************\n",
      "Cutoff = 0.52\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.99      0.67      0.80     25566\n",
      "    class 1       0.04      0.77      0.07       439\n",
      "\n",
      "avg / total       0.98      0.68      0.79     26005\n",
      "\n",
      "[[17250  8316]\n",
      " [  101   338]]\n",
      "*********************************************************\n",
      "Cutoff = 0.53\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.99      0.70      0.82     25566\n",
      "    class 1       0.04      0.74      0.08       439\n",
      "\n",
      "avg / total       0.98      0.70      0.81     26005\n",
      "\n",
      "[[17928  7638]\n",
      " [  113   326]]\n",
      "*********************************************************\n",
      "Cutoff = 0.54\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.99      0.72      0.84     25566\n",
      "    class 1       0.04      0.71      0.08       439\n",
      "\n",
      "avg / total       0.98      0.72      0.83     26005\n",
      "\n",
      "[[18533  7033]\n",
      " [  128   311]]\n",
      "*********************************************************\n",
      "Cutoff = 0.55\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.99      0.75      0.85     25566\n",
      "    class 1       0.04      0.69      0.08       439\n",
      "\n",
      "avg / total       0.98      0.74      0.84     26005\n",
      "\n",
      "[[19047  6519]\n",
      " [  136   303]]\n",
      "*********************************************************\n",
      "Cutoff = 0.56\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.99      0.76      0.86     25566\n",
      "    class 1       0.05      0.67      0.09       439\n",
      "\n",
      "avg / total       0.98      0.76      0.85     26005\n",
      "\n",
      "[[19494  6072]\n",
      " [  145   294]]\n",
      "*********************************************************\n",
      "Cutoff = 0.57\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.99      0.78      0.87     25566\n",
      "    class 1       0.05      0.64      0.09       439\n",
      "\n",
      "avg / total       0.98      0.78      0.86     26005\n",
      "\n",
      "[[19894  5672]\n",
      " [  156   283]]\n",
      "*********************************************************\n",
      "Cutoff = 0.58\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.99      0.79      0.88     25566\n",
      "    class 1       0.05      0.63      0.09       439\n",
      "\n",
      "avg / total       0.98      0.79      0.87     26005\n",
      "\n",
      "[[20295  5271]\n",
      " [  164   275]]\n",
      "*********************************************************\n",
      "Cutoff = 0.59\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.99      0.81      0.89     25566\n",
      "    class 1       0.05      0.61      0.10       439\n",
      "\n",
      "avg / total       0.98      0.80      0.88     26005\n",
      "\n",
      "[[20653  4913]\n",
      " [  171   268]]\n",
      "*********************************************************\n",
      "Cutoff = 0.6\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.99      0.82      0.90     25566\n",
      "    class 1       0.05      0.58      0.10       439\n",
      "\n",
      "avg / total       0.98      0.82      0.88     26005\n",
      "\n",
      "[[20965  4601]\n",
      " [  185   254]]\n",
      "*********************************************************\n",
      "Cutoff = 0.61\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.99      0.83      0.91     25566\n",
      "    class 1       0.05      0.56      0.10       439\n",
      "\n",
      "avg / total       0.98      0.83      0.89     26005\n",
      "\n",
      "[[21296  4270]\n",
      " [  191   248]]\n",
      "*********************************************************\n",
      "Cutoff = 0.62\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.99      0.84      0.91     25566\n",
      "    class 1       0.06      0.55      0.10       439\n",
      "\n",
      "avg / total       0.98      0.84      0.90     26005\n",
      "\n",
      "[[21550  4016]\n",
      " [  198   241]]\n",
      "*********************************************************\n",
      "Cutoff = 0.63\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.99      0.85      0.92     25566\n",
      "    class 1       0.06      0.54      0.11       439\n",
      "\n",
      "avg / total       0.97      0.85      0.90     26005\n",
      "\n",
      "[[21796  3770]\n",
      " [  204   235]]\n",
      "*********************************************************\n",
      "Cutoff = 0.64\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.99      0.86      0.92     25566\n",
      "    class 1       0.06      0.51      0.11       439\n",
      "\n",
      "avg / total       0.97      0.86      0.91     26005\n",
      "\n",
      "[[22039  3527]\n",
      " [  215   224]]\n",
      "*********************************************************\n",
      "Cutoff = 0.65\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.99      0.87      0.93     25566\n",
      "    class 1       0.06      0.49      0.11       439\n",
      "\n",
      "avg / total       0.97      0.87      0.91     26005\n",
      "\n",
      "[[22282  3284]\n",
      " [  223   216]]\n",
      "*********************************************************\n",
      "Cutoff = 0.66\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.99      0.88      0.93     25566\n",
      "    class 1       0.06      0.46      0.11       439\n",
      "\n",
      "avg / total       0.97      0.87      0.92     26005\n",
      "\n",
      "[[22492  3074]\n",
      " [  236   203]]\n",
      "*********************************************************\n",
      "Cutoff = 0.67\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.99      0.89      0.94     25566\n",
      "    class 1       0.06      0.44      0.11       439\n",
      "\n",
      "avg / total       0.97      0.88      0.92     26005\n",
      "\n",
      "[[22698  2868]\n",
      " [  248   191]]\n",
      "*********************************************************\n",
      "Cutoff = 0.68\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.99      0.90      0.94     25566\n",
      "    class 1       0.06      0.41      0.11       439\n",
      "\n",
      "avg / total       0.97      0.89      0.93     26005\n",
      "\n",
      "[[22885  2681]\n",
      " [  259   180]]\n",
      "*********************************************************\n",
      "Cutoff = 0.69\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.99      0.90      0.94     25566\n",
      "    class 1       0.06      0.39      0.11       439\n",
      "\n",
      "avg / total       0.97      0.89      0.93     26005\n",
      "\n",
      "[[23072  2494]\n",
      " [  267   172]]\n",
      "*********************************************************\n",
      "Cutoff = 0.7\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.99      0.91      0.95     25566\n",
      "    class 1       0.07      0.38      0.11       439\n",
      "\n",
      "avg / total       0.97      0.90      0.93     26005\n",
      "\n",
      "[[23254  2312]\n",
      " [  274   165]]\n",
      "*********************************************************\n",
      "Cutoff = 0.71\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.99      0.92      0.95     25566\n",
      "    class 1       0.07      0.36      0.12       439\n",
      "\n",
      "avg / total       0.97      0.91      0.94     26005\n",
      "\n",
      "[[23429  2137]\n",
      " [  279   160]]\n",
      "*********************************************************\n",
      "Cutoff = 0.72\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.99      0.92      0.95     25566\n",
      "    class 1       0.07      0.34      0.12       439\n",
      "\n",
      "avg / total       0.97      0.91      0.94     26005\n",
      "\n",
      "[[23581  1985]\n",
      " [  290   149]]\n",
      "*********************************************************\n",
      "Cutoff = 0.73\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.99      0.93      0.96     25566\n",
      "    class 1       0.07      0.32      0.12       439\n",
      "\n",
      "avg / total       0.97      0.92      0.94     26005\n",
      "\n",
      "[[23707  1859]\n",
      " [  297   142]]\n",
      "*********************************************************\n",
      "Cutoff = 0.74\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.99      0.93      0.96     25566\n",
      "    class 1       0.07      0.31      0.12       439\n",
      "\n",
      "avg / total       0.97      0.92      0.94     26005\n",
      "\n",
      "[[23839  1727]\n",
      " [  305   134]]\n",
      "*********************************************************\n",
      "Cutoff = 0.75\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.99      0.94      0.96     25566\n",
      "    class 1       0.07      0.28      0.11       439\n",
      "\n",
      "avg / total       0.97      0.93      0.95     26005\n",
      "\n",
      "[[23991  1575]\n",
      " [  317   122]]\n",
      "*********************************************************\n",
      "Cutoff = 0.76\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.99      0.94      0.96     25566\n",
      "    class 1       0.07      0.26      0.11       439\n",
      "\n",
      "avg / total       0.97      0.93      0.95     26005\n",
      "\n",
      "[[24121  1445]\n",
      " [  326   113]]\n",
      "*********************************************************\n",
      "Cutoff = 0.77\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.99      0.95      0.97     25566\n",
      "    class 1       0.08      0.25      0.12       439\n",
      "\n",
      "avg / total       0.97      0.94      0.95     26005\n",
      "\n",
      "[[24240  1326]\n",
      " [  330   109]]\n",
      "*********************************************************\n",
      "Cutoff = 0.78\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.99      0.95      0.97     25566\n",
      "    class 1       0.08      0.24      0.12       439\n",
      "\n",
      "avg / total       0.97      0.94      0.95     26005\n",
      "\n",
      "[[24346  1220]\n",
      " [  334   105]]\n",
      "*********************************************************\n",
      "Cutoff = 0.79\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.99      0.96      0.97     25566\n",
      "    class 1       0.08      0.22      0.12       439\n",
      "\n",
      "avg / total       0.97      0.94      0.96     26005\n",
      "\n",
      "[[24439  1127]\n",
      " [  342    97]]\n",
      "*********************************************************\n",
      "Cutoff = 0.8\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.99      0.96      0.97     25566\n",
      "    class 1       0.08      0.20      0.11       439\n",
      "\n",
      "avg / total       0.97      0.95      0.96     26005\n",
      "\n",
      "[[24540  1026]\n",
      " [  353    86]]\n",
      "*********************************************************\n",
      "Cutoff = 0.81\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.99      0.96      0.97     25566\n",
      "    class 1       0.08      0.18      0.11       439\n",
      "\n",
      "avg / total       0.97      0.95      0.96     26005\n",
      "\n",
      "[[24643   923]\n",
      " [  360    79]]\n",
      "*********************************************************\n",
      "Cutoff = 0.82\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.99      0.97      0.98     25566\n",
      "    class 1       0.08      0.17      0.11       439\n",
      "\n",
      "avg / total       0.97      0.95      0.96     26005\n",
      "\n",
      "[[24737   829]\n",
      " [  365    74]]\n",
      "*********************************************************\n",
      "Cutoff = 0.83\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.99      0.97      0.98     25566\n",
      "    class 1       0.08      0.15      0.10       439\n",
      "\n",
      "avg / total       0.97      0.96      0.96     26005\n",
      "\n",
      "[[24816   750]\n",
      " [  374    65]]\n",
      "*********************************************************\n",
      "Cutoff = 0.84\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.99      0.97      0.98     25566\n",
      "    class 1       0.09      0.14      0.11       439\n",
      "\n",
      "avg / total       0.97      0.96      0.97     26005\n",
      "\n",
      "[[24913   653]\n",
      " [  377    62]]\n",
      "*********************************************************\n",
      "Cutoff = 0.85\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.99      0.98      0.98     25566\n",
      "    class 1       0.10      0.13      0.11       439\n",
      "\n",
      "avg / total       0.97      0.96      0.97     26005\n",
      "\n",
      "[[25007   559]\n",
      " [  380    59]]\n",
      "*********************************************************\n",
      "Cutoff = 0.86\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.98      0.98      0.98     25566\n",
      "    class 1       0.10      0.12      0.11       439\n",
      "\n",
      "avg / total       0.97      0.97      0.97     26005\n",
      "\n",
      "[[25085   481]\n",
      " [  387    52]]\n",
      "*********************************************************\n",
      "Cutoff = 0.87\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.98      0.98      0.98     25566\n",
      "    class 1       0.10      0.11      0.11       439\n",
      "\n",
      "avg / total       0.97      0.97      0.97     26005\n",
      "\n",
      "[[25149   417]\n",
      " [  391    48]]\n",
      "*********************************************************\n",
      "Cutoff = 0.88\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.98      0.99      0.99     25566\n",
      "    class 1       0.11      0.10      0.10       439\n",
      "\n",
      "avg / total       0.97      0.97      0.97     26005\n",
      "\n",
      "[[25218   348]\n",
      " [  397    42]]\n",
      "*********************************************************\n",
      "Cutoff = 0.89\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.98      0.99      0.99     25566\n",
      "    class 1       0.11      0.08      0.10       439\n",
      "\n",
      "avg / total       0.97      0.97      0.97     26005\n",
      "\n",
      "[[25267   299]\n",
      " [  402    37]]\n",
      "*********************************************************\n",
      "Cutoff = 0.9\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.98      0.99      0.99     25566\n",
      "    class 1       0.10      0.07      0.08       439\n",
      "\n",
      "avg / total       0.97      0.97      0.97     26005\n",
      "\n",
      "[[25318   248]\n",
      " [  410    29]]\n",
      "*********************************************************\n",
      "Cutoff = 0.91\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.98      0.99      0.99     25566\n",
      "    class 1       0.11      0.05      0.07       439\n",
      "\n",
      "avg / total       0.97      0.98      0.97     26005\n",
      "\n",
      "[[25373   193]\n",
      " [  416    23]]\n",
      "*********************************************************\n",
      "Cutoff = 0.92\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.98      0.99      0.99     25566\n",
      "    class 1       0.11      0.04      0.06       439\n",
      "\n",
      "avg / total       0.97      0.98      0.97     26005\n",
      "\n",
      "[[25424   142]\n",
      " [  421    18]]\n",
      "*********************************************************\n",
      "Cutoff = 0.93\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.98      1.00      0.99     25566\n",
      "    class 1       0.08      0.02      0.04       439\n",
      "\n",
      "avg / total       0.97      0.98      0.97     26005\n",
      "\n",
      "[[25450   116]\n",
      " [  429    10]]\n",
      "*********************************************************\n",
      "Cutoff = 0.94\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.98      1.00      0.99     25566\n",
      "    class 1       0.07      0.01      0.02       439\n",
      "\n",
      "avg / total       0.97      0.98      0.97     26005\n",
      "\n",
      "[[25484    82]\n",
      " [  433     6]]\n",
      "*********************************************************\n",
      "Cutoff = 0.95\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.98      1.00      0.99     25566\n",
      "    class 1       0.08      0.01      0.02       439\n",
      "\n",
      "avg / total       0.97      0.98      0.97     26005\n",
      "\n",
      "[[25518    48]\n",
      " [  435     4]]\n",
      "*********************************************************\n",
      "Cutoff = 0.96\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.98      1.00      0.99     25566\n",
      "    class 1       0.09      0.01      0.01       439\n",
      "\n",
      "avg / total       0.97      0.98      0.97     26005\n",
      "\n",
      "[[25537    29]\n",
      " [  436     3]]\n",
      "*********************************************************\n",
      "Cutoff = 0.97\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.98      1.00      0.99     25566\n",
      "    class 1       0.19      0.01      0.01       439\n",
      "\n",
      "avg / total       0.97      0.98      0.97     26005\n",
      "\n",
      "[[25553    13]\n",
      " [  436     3]]\n",
      "*********************************************************\n",
      "Cutoff = 0.98\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.98      1.00      0.99     25566\n",
      "    class 1       0.00      0.00      0.00       439\n",
      "\n",
      "avg / total       0.97      0.98      0.97     26005\n",
      "\n",
      "[[25562     4]\n",
      " [  439     0]]\n",
      "*********************************************************\n",
      "Cutoff = 0.99\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.98      1.00      0.99     25566\n",
      "    class 1       0.00      0.00      0.00       439\n",
      "\n",
      "avg / total       0.97      0.98      0.97     26005\n",
      "\n",
      "[[25565     1]\n",
      " [  439     0]]\n",
      "*********************************************************\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "def drange(start, stop, step):\n",
    "    while start < stop:\n",
    "            yield start\n",
    "            start += step\n",
    "\n",
    "\n",
    "for j in drange(0.0, 1.0, 0.01):\n",
    "    cutoff = j\n",
    "    y_pred = list()\n",
    "    for i in range(0,len(y_submission)):\n",
    "        if y_submission[i] > cutoff:\n",
    "            y_pred.append(1)\n",
    "        else:\n",
    "            y_pred.append(0)\n",
    "    target_names = ['class 0', 'class 1']\n",
    "    print \"Cutoff = {}\".format(cutoff)\n",
    "    print(classification_report(y_suhas, y_pred, target_names=target_names))\n",
    "    print confusion_matrix(y_suhas, y_pred)\n",
    "    print(\"*********************************************************\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "86681"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_submission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cutoff = 0.76\n",
    "y_pred = list()\n",
    "for i in range(0,len(y_submission)):\n",
    "    if y_submission[i] > cutoff:\n",
    "        y_pred.append(1)\n",
    "    else:\n",
    "        y_pred.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86681\n",
      "4161\n"
     ]
    }
   ],
   "source": [
    "print len(y_pred)\n",
    "print sum(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import the train dataset\n",
    "data_test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({'user_id': data_test['user_id'], 'prediction(adopter)':y_pred})\n",
    "submission = submission[['user_id', 'prediction(adopter)']]\n",
    "submission.to_csv(\"stacking_result_29th_Nov_0.76_new.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
