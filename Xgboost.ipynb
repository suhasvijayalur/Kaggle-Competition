{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"font-family:Times New Roman;\">Kaggle Competition</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-family:Times New Roman;\"><b><font size = \"4\">Suhas Alur</font></b></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"font-family:Times New Roman;\">Loading & Pre-processing</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Suhas\\Documents\\MSBA\\Semester Two\\Predictive Analytics\\Homework\\Homework - 5\\Data\n"
     ]
    }
   ],
   "source": [
    "# import necessary libraries and specify that graphs should be plotted inline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import svm, datasets\n",
    "%cd 'C:\\Users\\Suhas\\Documents\\MSBA\\Semester Two\\Predictive Analytics\\Homework\\Homework - 5\\Data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import the train dataset\n",
    "data_train = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Splitting the dataset based on attributes and target variable\n",
    "X = data_train.iloc[:,0:25]\n",
    "y = data_train.adopter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = np.array(X)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Splitting the train data into training and testing\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.05842009  0.00560829  0.05431093  0.05853635  0.05116341  0.04855876\n",
      "  0.03421883  0.06479198  0.06900566  0.0406228   0.03947478  0.05699944\n",
      "  0.03977114  0.05467344  0.03762078  0.02791376  0.02742831  0.06248462\n",
      "  0.05075311  0.0101801   0.00647335  0.0362107   0.05798579  0.00578673\n",
      "  0.00100685]\n"
     ]
    }
   ],
   "source": [
    "# Feature Importance\n",
    "from sklearn import datasets\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "# fit an Extra Trees model to the data\n",
    "model = ExtraTreesClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# display the relative importance of each attribute\n",
    "print(model.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Suhas\\Anaconda2\\lib\\site-packages\\sklearn\\cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60677L, 17L)\n",
      "(26005L, 17L)\n",
      "[[  7.51170388e-04   4.58571813e-03  -3.20929346e-04   9.98648393e-05\n",
      "    0.00000000e+00   1.12705254e-03   1.14693996e-02   2.86745898e-07\n",
      "    5.44987216e-05  -4.48150767e-06   3.42459459e-03   3.09590930e-05\n",
      "    1.48865190e-04   0.00000000e+00   0.00000000e+00   4.19881421e-03\n",
      "   -7.90620612e-03   2.28363605e-06  -3.47932254e-05  -1.40759988e-04\n",
      "    0.00000000e+00   3.09485239e-04  -1.03370173e-04  -1.26918595e-02\n",
      "    0.00000000e+00]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Suhas\\Anaconda2\\lib\\site-packages\\sklearn\\utils\\deprecation.py:70: DeprecationWarning: Function transform is deprecated; Support to use estimators as feature selectors will be removed in version 0.19. Use SelectFromModel instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "C:\\Users\\Suhas\\Anaconda2\\lib\\site-packages\\sklearn\\utils\\deprecation.py:70: DeprecationWarning: Function transform is deprecated; Support to use estimators as feature selectors will be removed in version 0.19. Use SelectFromModel instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.cross_validation import train_test_split\n",
    "svc = LinearSVC(C=0.01, penalty=\"l1\", dual=False)\n",
    "\n",
    "X_train_new = svc.fit_transform(X_train, y_train)\n",
    "print(X_train_new.shape)\n",
    "\n",
    "X_test_new = svc.transform(X_test)\n",
    "print(X_test_new.shape)\n",
    "print(svc.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"font-family:Times New Roman;\">Gradient Boosted Trees</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "mingw_path = 'C:\\\\Program Files\\\\mingw-w64\\\\x86_64-6.2.0-posix-seh-rt_v5-rev1\\\\mingw64\\\\bin'\n",
    "os.environ['PATH'] = mingw_path + ';' + os.environ['PATH']\n",
    "\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = xgb.XGBClassifier(\n",
    " learning_rate =0.8,\n",
    " n_estimators=100,\n",
    " max_depth=2,\n",
    " min_child_weight=6,\n",
    " gamma=5,\n",
    " subsample=1,\n",
    " colsample_bytree=0.5,\n",
    " reg_lambda = 0.01,\n",
    " #reg_alpha=1,\n",
    " objective= 'binary:logistic',\n",
    " nthread=10,\n",
    " scale_pos_weight=1,\n",
    " seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = xgb.XGBClassifier(learning_rate =0.8, n_estimators=100, max_depth=2, min_child_weight=6, gamma=5, subsample=1, colsample_bytree=0.5, reg_alpha=0.1, objective= 'binary:logistic', nthread=10, scale_pos_weight=1, seed=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#from sklearn.ensemble import AdaBoostClassifier\n",
    "#clf = AdaBoostClassifier(base_estimator = model, n_estimators=100, learning_rate = 0.1, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predicted = model.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cutoff = 0.0\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.00      0.00      0.00     25566\n",
      "    class 1       0.02      1.00      0.03       439\n",
      "\n",
      "avg / total       0.00      0.02      0.00     26005\n",
      "\n",
      "[[    0 25566]\n",
      " [    0   439]]\n",
      "*********************************************************\n",
      "Cutoff = 0.01\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       1.00      0.55      0.71     25566\n",
      "    class 1       0.03      0.88      0.06       439\n",
      "\n",
      "avg / total       0.98      0.56      0.70     26005\n",
      "\n",
      "[[14151 11415]\n",
      " [   51   388]]\n",
      "*********************************************************\n",
      "Cutoff = 0.02\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.99      0.74      0.85     25566\n",
      "    class 1       0.04      0.69      0.08       439\n",
      "\n",
      "avg / total       0.98      0.74      0.83     26005\n",
      "\n",
      "[[18848  6718]\n",
      " [  134   305]]\n",
      "*********************************************************\n",
      "Cutoff = 0.03\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.99      0.83      0.91     25566\n",
      "    class 1       0.05      0.56      0.10       439\n",
      "\n",
      "avg / total       0.98      0.83      0.89     26005\n",
      "\n",
      "[[21299  4267]\n",
      " [  191   248]]\n",
      "*********************************************************\n",
      "Cutoff = 0.04\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.99      0.89      0.94     25566\n",
      "    class 1       0.06      0.44      0.11       439\n",
      "\n",
      "avg / total       0.97      0.88      0.92     26005\n",
      "\n",
      "[[22681  2885]\n",
      " [  244   195]]\n",
      "*********************************************************\n",
      "Cutoff = 0.05\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.99      0.92      0.95     25566\n",
      "    class 1       0.07      0.35      0.12       439\n",
      "\n",
      "avg / total       0.97      0.91      0.94     26005\n",
      "\n",
      "[[23567  1999]\n",
      " [  286   153]]\n",
      "*********************************************************\n",
      "Cutoff = 0.06\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.99      0.94      0.96     25566\n",
      "    class 1       0.08      0.28      0.12       439\n",
      "\n",
      "avg / total       0.97      0.93      0.95     26005\n",
      "\n",
      "[[24089  1477]\n",
      " [  316   123]]\n",
      "*********************************************************\n",
      "Cutoff = 0.07\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.99      0.96      0.97     25566\n",
      "    class 1       0.08      0.22      0.12       439\n",
      "\n",
      "avg / total       0.97      0.94      0.96     26005\n",
      "\n",
      "[[24461  1105]\n",
      " [  341    98]]\n",
      "*********************************************************\n",
      "Cutoff = 0.08\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.99      0.97      0.98     25566\n",
      "    class 1       0.09      0.18      0.12       439\n",
      "\n",
      "avg / total       0.97      0.95      0.96     26005\n",
      "\n",
      "[[24735   831]\n",
      " [  361    78]]\n",
      "*********************************************************\n",
      "Cutoff = 0.09\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.99      0.98      0.98     25566\n",
      "    class 1       0.10      0.15      0.12       439\n",
      "\n",
      "avg / total       0.97      0.96      0.97     26005\n",
      "\n",
      "[[24934   632]\n",
      " [  371    68]]\n",
      "*********************************************************\n",
      "Cutoff = 0.1\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.98      0.98      0.98     25566\n",
      "    class 1       0.10      0.13      0.12       439\n",
      "\n",
      "avg / total       0.97      0.97      0.97     26005\n",
      "\n",
      "[[25072   494]\n",
      " [  382    57]]\n",
      "*********************************************************\n",
      "Cutoff = 0.11\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.98      0.98      0.98     25566\n",
      "    class 1       0.09      0.09      0.09       439\n",
      "\n",
      "avg / total       0.97      0.97      0.97     26005\n",
      "\n",
      "[[25174   392]\n",
      " [  401    38]]\n",
      "*********************************************************\n",
      "Cutoff = 0.12\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.98      0.99      0.99     25566\n",
      "    class 1       0.09      0.07      0.08       439\n",
      "\n",
      "avg / total       0.97      0.97      0.97     26005\n",
      "\n",
      "[[25251   315]\n",
      " [  409    30]]\n",
      "*********************************************************\n",
      "Cutoff = 0.13\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.98      0.99      0.99     25566\n",
      "    class 1       0.08      0.05      0.06       439\n",
      "\n",
      "avg / total       0.97      0.97      0.97     26005\n",
      "\n",
      "[[25304   262]\n",
      " [  416    23]]\n",
      "*********************************************************\n",
      "Cutoff = 0.14\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.98      0.99      0.99     25566\n",
      "    class 1       0.08      0.05      0.06       439\n",
      "\n",
      "avg / total       0.97      0.98      0.97     26005\n",
      "\n",
      "[[25346   220]\n",
      " [  419    20]]\n",
      "*********************************************************\n",
      "Cutoff = 0.15\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.98      0.99      0.99     25566\n",
      "    class 1       0.06      0.03      0.03       439\n",
      "\n",
      "avg / total       0.97      0.98      0.97     26005\n",
      "\n",
      "[[25378   188]\n",
      " [  428    11]]\n",
      "*********************************************************\n",
      "Cutoff = 0.16\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.98      0.99      0.99     25566\n",
      "    class 1       0.05      0.02      0.03       439\n",
      "\n",
      "avg / total       0.97      0.98      0.97     26005\n",
      "\n",
      "[[25406   160]\n",
      " [  431     8]]\n",
      "*********************************************************\n",
      "Cutoff = 0.17\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.98      0.99      0.99     25566\n",
      "    class 1       0.04      0.01      0.02       439\n",
      "\n",
      "avg / total       0.97      0.98      0.97     26005\n",
      "\n",
      "[[25430   136]\n",
      " [  433     6]]\n",
      "*********************************************************\n",
      "Cutoff = 0.18\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.98      1.00      0.99     25566\n",
      "    class 1       0.04      0.01      0.02       439\n",
      "\n",
      "avg / total       0.97      0.98      0.97     26005\n",
      "\n",
      "[[25458   108]\n",
      " [  434     5]]\n",
      "*********************************************************\n",
      "Cutoff = 0.19\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.98      1.00      0.99     25566\n",
      "    class 1       0.05      0.01      0.02       439\n",
      "\n",
      "avg / total       0.97      0.98      0.97     26005\n",
      "\n",
      "[[25478    88]\n",
      " [  434     5]]\n",
      "*********************************************************\n",
      "Cutoff = 0.2\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.98      1.00      0.99     25566\n",
      "    class 1       0.06      0.01      0.02       439\n",
      "\n",
      "avg / total       0.97      0.98      0.97     26005\n",
      "\n",
      "[[25493    73]\n",
      " [  434     5]]\n",
      "*********************************************************\n",
      "Cutoff = 0.21\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.98      1.00      0.99     25566\n",
      "    class 1       0.07      0.01      0.02       439\n",
      "\n",
      "avg / total       0.97      0.98      0.97     26005\n",
      "\n",
      "[[25503    63]\n",
      " [  434     5]]\n",
      "*********************************************************\n",
      "Cutoff = 0.22\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.98      1.00      0.99     25566\n",
      "    class 1       0.07      0.01      0.02       439\n",
      "\n",
      "avg / total       0.97      0.98      0.97     26005\n",
      "\n",
      "[[25509    57]\n",
      " [  435     4]]\n",
      "*********************************************************\n",
      "Cutoff = 0.23\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.98      1.00      0.99     25566\n",
      "    class 1       0.08      0.01      0.02       439\n",
      "\n",
      "avg / total       0.97      0.98      0.97     26005\n",
      "\n",
      "[[25519    47]\n",
      " [  435     4]]\n",
      "*********************************************************\n",
      "Cutoff = 0.24\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.98      1.00      0.99     25566\n",
      "    class 1       0.09      0.01      0.02       439\n",
      "\n",
      "avg / total       0.97      0.98      0.97     26005\n",
      "\n",
      "[[25526    40]\n",
      " [  435     4]]\n",
      "*********************************************************\n",
      "Cutoff = 0.25\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.98      1.00      0.99     25566\n",
      "    class 1       0.11      0.01      0.02       439\n",
      "\n",
      "avg / total       0.97      0.98      0.97     26005\n",
      "\n",
      "[[25532    34]\n",
      " [  435     4]]\n",
      "*********************************************************\n",
      "Cutoff = 0.26\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.98      1.00      0.99     25566\n",
      "    class 1       0.10      0.01      0.01       439\n",
      "\n",
      "avg / total       0.97      0.98      0.97     26005\n",
      "\n",
      "[[25539    27]\n",
      " [  436     3]]\n",
      "*********************************************************\n",
      "Cutoff = 0.27\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.98      1.00      0.99     25566\n",
      "    class 1       0.11      0.01      0.01       439\n",
      "\n",
      "avg / total       0.97      0.98      0.97     26005\n",
      "\n",
      "[[25541    25]\n",
      " [  436     3]]\n",
      "*********************************************************\n",
      "Cutoff = 0.28\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.98      1.00      0.99     25566\n",
      "    class 1       0.12      0.01      0.01       439\n",
      "\n",
      "avg / total       0.97      0.98      0.97     26005\n",
      "\n",
      "[[25545    21]\n",
      " [  436     3]]\n",
      "*********************************************************\n",
      "Cutoff = 0.29\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.98      1.00      0.99     25566\n",
      "    class 1       0.14      0.01      0.01       439\n",
      "\n",
      "avg / total       0.97      0.98      0.97     26005\n",
      "\n",
      "[[25547    19]\n",
      " [  436     3]]\n",
      "*********************************************************\n",
      "Cutoff = 0.3\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.98      1.00      0.99     25566\n",
      "    class 1       0.18      0.01      0.01       439\n",
      "\n",
      "avg / total       0.97      0.98      0.97     26005\n",
      "\n",
      "[[25552    14]\n",
      " [  436     3]]\n",
      "*********************************************************\n",
      "Cutoff = 0.31\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.98      1.00      0.99     25566\n",
      "    class 1       0.15      0.00      0.01       439\n",
      "\n",
      "avg / total       0.97      0.98      0.97     26005\n",
      "\n",
      "[[25555    11]\n",
      " [  437     2]]\n",
      "*********************************************************\n",
      "Cutoff = 0.32\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.98      1.00      0.99     25566\n",
      "    class 1       0.15      0.00      0.01       439\n",
      "\n",
      "avg / total       0.97      0.98      0.97     26005\n",
      "\n",
      "[[25555    11]\n",
      " [  437     2]]\n",
      "*********************************************************\n",
      "Cutoff = 0.33\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.98      1.00      0.99     25566\n",
      "    class 1       0.08      0.00      0.00       439\n",
      "\n",
      "avg / total       0.97      0.98      0.97     26005\n",
      "\n",
      "[[25555    11]\n",
      " [  438     1]]\n",
      "*********************************************************\n",
      "Cutoff = 0.34\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.98      1.00      0.99     25566\n",
      "    class 1       0.10      0.00      0.00       439\n",
      "\n",
      "avg / total       0.97      0.98      0.97     26005\n",
      "\n",
      "[[25557     9]\n",
      " [  438     1]]\n",
      "*********************************************************\n",
      "Cutoff = 0.35\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.98      1.00      0.99     25566\n",
      "    class 1       0.11      0.00      0.00       439\n",
      "\n",
      "avg / total       0.97      0.98      0.97     26005\n",
      "\n",
      "[[25558     8]\n",
      " [  438     1]]\n",
      "*********************************************************\n",
      "Cutoff = 0.36\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.98      1.00      0.99     25566\n",
      "    class 1       0.11      0.00      0.00       439\n",
      "\n",
      "avg / total       0.97      0.98      0.97     26005\n",
      "\n",
      "[[25558     8]\n",
      " [  438     1]]\n",
      "*********************************************************\n",
      "Cutoff = 0.37\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.98      1.00      0.99     25566\n",
      "    class 1       0.11      0.00      0.00       439\n",
      "\n",
      "avg / total       0.97      0.98      0.97     26005\n",
      "\n",
      "[[25558     8]\n",
      " [  438     1]]\n",
      "*********************************************************\n",
      "Cutoff = 0.38\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.98      1.00      0.99     25566\n",
      "    class 1       0.11      0.00      0.00       439\n",
      "\n",
      "avg / total       0.97      0.98      0.97     26005\n",
      "\n",
      "[[25558     8]\n",
      " [  438     1]]\n",
      "*********************************************************\n",
      "Cutoff = 0.39\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.98      1.00      0.99     25566\n",
      "    class 1       0.12      0.00      0.00       439\n",
      "\n",
      "avg / total       0.97      0.98      0.97     26005\n",
      "\n",
      "[[25559     7]\n",
      " [  438     1]]\n",
      "*********************************************************\n",
      "Cutoff = 0.4\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.98      1.00      0.99     25566\n",
      "    class 1       0.14      0.00      0.00       439\n",
      "\n",
      "avg / total       0.97      0.98      0.97     26005\n",
      "\n",
      "[[25560     6]\n",
      " [  438     1]]\n",
      "*********************************************************\n",
      "Cutoff = 0.41\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.98      1.00      0.99     25566\n",
      "    class 1       0.14      0.00      0.00       439\n",
      "\n",
      "avg / total       0.97      0.98      0.97     26005\n",
      "\n",
      "[[25560     6]\n",
      " [  438     1]]\n",
      "*********************************************************\n",
      "Cutoff = 0.42\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.98      1.00      0.99     25566\n",
      "    class 1       0.17      0.00      0.00       439\n",
      "\n",
      "avg / total       0.97      0.98      0.97     26005\n",
      "\n",
      "[[25561     5]\n",
      " [  438     1]]\n",
      "*********************************************************\n",
      "Cutoff = 0.43\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.98      1.00      0.99     25566\n",
      "    class 1       0.17      0.00      0.00       439\n",
      "\n",
      "avg / total       0.97      0.98      0.97     26005\n",
      "\n",
      "[[25561     5]\n",
      " [  438     1]]\n",
      "*********************************************************\n",
      "Cutoff = 0.44\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.98      1.00      0.99     25566\n",
      "    class 1       0.17      0.00      0.00       439\n",
      "\n",
      "avg / total       0.97      0.98      0.97     26005\n",
      "\n",
      "[[25561     5]\n",
      " [  438     1]]\n",
      "*********************************************************\n",
      "Cutoff = 0.45\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.98      1.00      0.99     25566\n",
      "    class 1       0.20      0.00      0.00       439\n",
      "\n",
      "avg / total       0.97      0.98      0.97     26005\n",
      "\n",
      "[[25562     4]\n",
      " [  438     1]]\n",
      "*********************************************************\n",
      "Cutoff = 0.46\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.98      1.00      0.99     25566\n",
      "    class 1       0.25      0.00      0.00       439\n",
      "\n",
      "avg / total       0.97      0.98      0.97     26005\n",
      "\n",
      "[[25563     3]\n",
      " [  438     1]]\n",
      "*********************************************************\n",
      "Cutoff = 0.47\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.98      1.00      0.99     25566\n",
      "    class 1       0.00      0.00      0.00       439\n",
      "\n",
      "avg / total       0.97      0.98      0.97     26005\n",
      "\n",
      "[[25564     2]\n",
      " [  439     0]]\n",
      "*********************************************************\n",
      "Cutoff = 0.48\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.98      1.00      0.99     25566\n",
      "    class 1       0.00      0.00      0.00       439\n",
      "\n",
      "avg / total       0.97      0.98      0.97     26005\n",
      "\n",
      "[[25564     2]\n",
      " [  439     0]]\n",
      "*********************************************************\n",
      "Cutoff = 0.49\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.98      1.00      0.99     25566\n",
      "    class 1       0.00      0.00      0.00       439\n",
      "\n",
      "avg / total       0.97      0.98      0.97     26005\n",
      "\n",
      "[[25564     2]\n",
      " [  439     0]]\n",
      "*********************************************************\n",
      "Cutoff = 0.5\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.98      1.00      0.99     25566\n",
      "    class 1       0.00      0.00      0.00       439\n",
      "\n",
      "avg / total       0.97      0.98      0.97     26005\n",
      "\n",
      "[[25564     2]\n",
      " [  439     0]]\n",
      "*********************************************************\n",
      "Cutoff = 0.51\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.98      1.00      0.99     25566\n",
      "    class 1       0.00      0.00      0.00       439\n",
      "\n",
      "avg / total       0.97      0.98      0.97     26005\n",
      "\n",
      "[[25564     2]\n",
      " [  439     0]]\n",
      "*********************************************************\n",
      "Cutoff = 0.52\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.98      1.00      0.99     25566\n",
      "    class 1       0.00      0.00      0.00       439\n",
      "\n",
      "avg / total       0.97      0.98      0.97     26005\n",
      "\n",
      "[[25565     1]\n",
      " [  439     0]]\n",
      "*********************************************************\n",
      "Cutoff = 0.53\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.98      1.00      0.99     25566\n",
      "    class 1       0.00      0.00      0.00       439\n",
      "\n",
      "avg / total       0.97      0.98      0.97     26005\n",
      "\n",
      "[[25565     1]\n",
      " [  439     0]]\n",
      "*********************************************************\n",
      "Cutoff = 0.54\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.98      1.00      0.99     25566\n",
      "    class 1       0.00      0.00      0.00       439\n",
      "\n",
      "avg / total       0.97      0.98      0.97     26005\n",
      "\n",
      "[[25565     1]\n",
      " [  439     0]]\n",
      "*********************************************************\n",
      "Cutoff = 0.55\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.98      1.00      0.99     25566\n",
      "    class 1       0.00      0.00      0.00       439\n",
      "\n",
      "avg / total       0.97      0.98      0.97     26005\n",
      "\n",
      "[[25565     1]\n",
      " [  439     0]]\n",
      "*********************************************************\n",
      "Cutoff = 0.56\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.98      1.00      0.99     25566\n",
      "    class 1       0.00      0.00      0.00       439\n",
      "\n",
      "avg / total       0.97      0.98      0.97     26005\n",
      "\n",
      "[[25565     1]\n",
      " [  439     0]]\n",
      "*********************************************************\n",
      "Cutoff = 0.57\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.98      1.00      0.99     25566\n",
      "    class 1       0.00      0.00      0.00       439\n",
      "\n",
      "avg / total       0.97      0.98      0.97     26005\n",
      "\n",
      "[[25565     1]\n",
      " [  439     0]]\n",
      "*********************************************************\n",
      "Cutoff = 0.58\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.98      1.00      0.99     25566\n",
      "    class 1       0.00      0.00      0.00       439\n",
      "\n",
      "avg / total       0.97      0.98      0.97     26005\n",
      "\n",
      "[[25565     1]\n",
      " [  439     0]]\n",
      "*********************************************************\n",
      "Cutoff = 0.59\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.98      1.00      0.99     25566\n",
      "    class 1       0.00      0.00      0.00       439\n",
      "\n",
      "avg / total       0.97      0.98      0.97     26005\n",
      "\n",
      "[[25565     1]\n",
      " [  439     0]]\n",
      "*********************************************************\n",
      "Cutoff = 0.6\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.98      1.00      0.99     25566\n",
      "    class 1       0.00      0.00      0.00       439\n",
      "\n",
      "avg / total       0.97      0.98      0.97     26005\n",
      "\n",
      "[[25565     1]\n",
      " [  439     0]]\n",
      "*********************************************************\n",
      "Cutoff = 0.61\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.98      1.00      0.99     25566\n",
      "    class 1       0.00      0.00      0.00       439\n",
      "\n",
      "avg / total       0.97      0.98      0.97     26005\n",
      "\n",
      "[[25565     1]\n",
      " [  439     0]]\n",
      "*********************************************************\n",
      "Cutoff = 0.62\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.98      1.00      0.99     25566\n",
      "    class 1       0.00      0.00      0.00       439\n",
      "\n",
      "avg / total       0.97      0.98      0.97     26005\n",
      "\n",
      "[[25565     1]\n",
      " [  439     0]]\n",
      "*********************************************************\n",
      "Cutoff = 0.63\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.98      1.00      0.99     25566\n",
      "    class 1       0.00      0.00      0.00       439\n",
      "\n",
      "avg / total       0.97      0.98      0.97     26005\n",
      "\n",
      "[[25566     0]\n",
      " [  439     0]]\n",
      "*********************************************************\n",
      "Cutoff = 0.64\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.98      1.00      0.99     25566\n",
      "    class 1       0.00      0.00      0.00       439\n",
      "\n",
      "avg / total       0.97      0.98      0.97     26005\n",
      "\n",
      "[[25566     0]\n",
      " [  439     0]]\n",
      "*********************************************************\n",
      "Cutoff = 0.65\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.98      1.00      0.99     25566\n",
      "    class 1       0.00      0.00      0.00       439\n",
      "\n",
      "avg / total       0.97      0.98      0.97     26005\n",
      "\n",
      "[[25566     0]\n",
      " [  439     0]]\n",
      "*********************************************************\n",
      "Cutoff = 0.66\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.98      1.00      0.99     25566\n",
      "    class 1       0.00      0.00      0.00       439\n",
      "\n",
      "avg / total       0.97      0.98      0.97     26005\n",
      "\n",
      "[[25566     0]\n",
      " [  439     0]]\n",
      "*********************************************************\n",
      "Cutoff = 0.67\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.98      1.00      0.99     25566\n",
      "    class 1       0.00      0.00      0.00       439\n",
      "\n",
      "avg / total       0.97      0.98      0.97     26005\n",
      "\n",
      "[[25566     0]\n",
      " [  439     0]]\n",
      "*********************************************************\n",
      "Cutoff = 0.68\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.98      1.00      0.99     25566\n",
      "    class 1       0.00      0.00      0.00       439\n",
      "\n",
      "avg / total       0.97      0.98      0.97     26005\n",
      "\n",
      "[[25566     0]\n",
      " [  439     0]]\n",
      "*********************************************************\n",
      "Cutoff = 0.69\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.98      1.00      0.99     25566\n",
      "    class 1       0.00      0.00      0.00       439\n",
      "\n",
      "avg / total       0.97      0.98      0.97     26005\n",
      "\n",
      "[[25566     0]\n",
      " [  439     0]]\n",
      "*********************************************************\n",
      "Cutoff = 0.7\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.98      1.00      0.99     25566\n",
      "    class 1       0.00      0.00      0.00       439\n",
      "\n",
      "avg / total       0.97      0.98      0.97     26005\n",
      "\n",
      "[[25566     0]\n",
      " [  439     0]]\n",
      "*********************************************************\n",
      "Cutoff = 0.71\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.98      1.00      0.99     25566\n",
      "    class 1       0.00      0.00      0.00       439\n",
      "\n",
      "avg / total       0.97      0.98      0.97     26005\n",
      "\n",
      "[[25566     0]\n",
      " [  439     0]]\n",
      "*********************************************************\n",
      "Cutoff = 0.72\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.98      1.00      0.99     25566\n",
      "    class 1       0.00      0.00      0.00       439\n",
      "\n",
      "avg / total       0.97      0.98      0.97     26005\n",
      "\n",
      "[[25566     0]\n",
      " [  439     0]]\n",
      "*********************************************************\n",
      "Cutoff = 0.73\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.98      1.00      0.99     25566\n",
      "    class 1       0.00      0.00      0.00       439\n",
      "\n",
      "avg / total       0.97      0.98      0.97     26005\n",
      "\n",
      "[[25566     0]\n",
      " [  439     0]]\n",
      "*********************************************************\n",
      "Cutoff = 0.74\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.98      1.00      0.99     25566\n",
      "    class 1       0.00      0.00      0.00       439\n",
      "\n",
      "avg / total       0.97      0.98      0.97     26005\n",
      "\n",
      "[[25566     0]\n",
      " [  439     0]]\n",
      "*********************************************************\n",
      "Cutoff = 0.75\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.98      1.00      0.99     25566\n",
      "    class 1       0.00      0.00      0.00       439\n",
      "\n",
      "avg / total       0.97      0.98      0.97     26005\n",
      "\n",
      "[[25566     0]\n",
      " [  439     0]]\n",
      "*********************************************************\n",
      "Cutoff = 0.76\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.98      1.00      0.99     25566\n",
      "    class 1       0.00      0.00      0.00       439\n",
      "\n",
      "avg / total       0.97      0.98      0.97     26005\n",
      "\n",
      "[[25566     0]\n",
      " [  439     0]]\n",
      "*********************************************************\n",
      "Cutoff = 0.77\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.98      1.00      0.99     25566\n",
      "    class 1       0.00      0.00      0.00       439\n",
      "\n",
      "avg / total       0.97      0.98      0.97     26005\n",
      "\n",
      "[[25566     0]\n",
      " [  439     0]]\n",
      "*********************************************************\n",
      "Cutoff = 0.78\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.98      1.00      0.99     25566\n",
      "    class 1       0.00      0.00      0.00       439\n",
      "\n",
      "avg / total       0.97      0.98      0.97     26005\n",
      "\n",
      "[[25566     0]\n",
      " [  439     0]]\n",
      "*********************************************************\n",
      "Cutoff = 0.79\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.98      1.00      0.99     25566\n",
      "    class 1       0.00      0.00      0.00       439\n",
      "\n",
      "avg / total       0.97      0.98      0.97     26005\n",
      "\n",
      "[[25566     0]\n",
      " [  439     0]]\n",
      "*********************************************************\n",
      "Cutoff = 0.8\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.98      1.00      0.99     25566\n",
      "    class 1       0.00      0.00      0.00       439\n",
      "\n",
      "avg / total       0.97      0.98      0.97     26005\n",
      "\n",
      "[[25566     0]\n",
      " [  439     0]]\n",
      "*********************************************************\n",
      "Cutoff = 0.81\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.98      1.00      0.99     25566\n",
      "    class 1       0.00      0.00      0.00       439\n",
      "\n",
      "avg / total       0.97      0.98      0.97     26005\n",
      "\n",
      "[[25566     0]\n",
      " [  439     0]]\n",
      "*********************************************************\n",
      "Cutoff = 0.82\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.98      1.00      0.99     25566\n",
      "    class 1       0.00      0.00      0.00       439\n",
      "\n",
      "avg / total       0.97      0.98      0.97     26005\n",
      "\n",
      "[[25566     0]\n",
      " [  439     0]]\n",
      "*********************************************************\n",
      "Cutoff = 0.83\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.98      1.00      0.99     25566\n",
      "    class 1       0.00      0.00      0.00       439\n",
      "\n",
      "avg / total       0.97      0.98      0.97     26005\n",
      "\n",
      "[[25566     0]\n",
      " [  439     0]]\n",
      "*********************************************************\n",
      "Cutoff = 0.84\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.98      1.00      0.99     25566\n",
      "    class 1       0.00      0.00      0.00       439\n",
      "\n",
      "avg / total       0.97      0.98      0.97     26005\n",
      "\n",
      "[[25566     0]\n",
      " [  439     0]]\n",
      "*********************************************************\n",
      "Cutoff = 0.85\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.98      1.00      0.99     25566\n",
      "    class 1       0.00      0.00      0.00       439\n",
      "\n",
      "avg / total       0.97      0.98      0.97     26005\n",
      "\n",
      "[[25566     0]\n",
      " [  439     0]]\n",
      "*********************************************************\n",
      "Cutoff = 0.86\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.98      1.00      0.99     25566\n",
      "    class 1       0.00      0.00      0.00       439\n",
      "\n",
      "avg / total       0.97      0.98      0.97     26005\n",
      "\n",
      "[[25566     0]\n",
      " [  439     0]]\n",
      "*********************************************************\n",
      "Cutoff = 0.87\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.98      1.00      0.99     25566\n",
      "    class 1       0.00      0.00      0.00       439\n",
      "\n",
      "avg / total       0.97      0.98      0.97     26005\n",
      "\n",
      "[[25566     0]\n",
      " [  439     0]]\n",
      "*********************************************************\n",
      "Cutoff = 0.88\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.98      1.00      0.99     25566\n",
      "    class 1       0.00      0.00      0.00       439\n",
      "\n",
      "avg / total       0.97      0.98      0.97     26005\n",
      "\n",
      "[[25566     0]\n",
      " [  439     0]]\n",
      "*********************************************************\n",
      "Cutoff = 0.89\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.98      1.00      0.99     25566\n",
      "    class 1       0.00      0.00      0.00       439\n",
      "\n",
      "avg / total       0.97      0.98      0.97     26005\n",
      "\n",
      "[[25566     0]\n",
      " [  439     0]]\n",
      "*********************************************************\n",
      "Cutoff = 0.9\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.98      1.00      0.99     25566\n",
      "    class 1       0.00      0.00      0.00       439\n",
      "\n",
      "avg / total       0.97      0.98      0.97     26005\n",
      "\n",
      "[[25566     0]\n",
      " [  439     0]]\n",
      "*********************************************************\n",
      "Cutoff = 0.91\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.98      1.00      0.99     25566\n",
      "    class 1       0.00      0.00      0.00       439\n",
      "\n",
      "avg / total       0.97      0.98      0.97     26005\n",
      "\n",
      "[[25566     0]\n",
      " [  439     0]]\n",
      "*********************************************************\n",
      "Cutoff = 0.92\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.98      1.00      0.99     25566\n",
      "    class 1       0.00      0.00      0.00       439\n",
      "\n",
      "avg / total       0.97      0.98      0.97     26005\n",
      "\n",
      "[[25566     0]\n",
      " [  439     0]]\n",
      "*********************************************************\n",
      "Cutoff = 0.93\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.98      1.00      0.99     25566\n",
      "    class 1       0.00      0.00      0.00       439\n",
      "\n",
      "avg / total       0.97      0.98      0.97     26005\n",
      "\n",
      "[[25566     0]\n",
      " [  439     0]]\n",
      "*********************************************************\n",
      "Cutoff = 0.94\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.98      1.00      0.99     25566\n",
      "    class 1       0.00      0.00      0.00       439\n",
      "\n",
      "avg / total       0.97      0.98      0.97     26005\n",
      "\n",
      "[[25566     0]\n",
      " [  439     0]]\n",
      "*********************************************************\n",
      "Cutoff = 0.95\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.98      1.00      0.99     25566\n",
      "    class 1       0.00      0.00      0.00       439\n",
      "\n",
      "avg / total       0.97      0.98      0.97     26005\n",
      "\n",
      "[[25566     0]\n",
      " [  439     0]]\n",
      "*********************************************************\n",
      "Cutoff = 0.96\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.98      1.00      0.99     25566\n",
      "    class 1       0.00      0.00      0.00       439\n",
      "\n",
      "avg / total       0.97      0.98      0.97     26005\n",
      "\n",
      "[[25566     0]\n",
      " [  439     0]]\n",
      "*********************************************************\n",
      "Cutoff = 0.97\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.98      1.00      0.99     25566\n",
      "    class 1       0.00      0.00      0.00       439\n",
      "\n",
      "avg / total       0.97      0.98      0.97     26005\n",
      "\n",
      "[[25566     0]\n",
      " [  439     0]]\n",
      "*********************************************************\n",
      "Cutoff = 0.98\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.98      1.00      0.99     25566\n",
      "    class 1       0.00      0.00      0.00       439\n",
      "\n",
      "avg / total       0.97      0.98      0.97     26005\n",
      "\n",
      "[[25566     0]\n",
      " [  439     0]]\n",
      "*********************************************************\n",
      "Cutoff = 0.99\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.98      1.00      0.99     25566\n",
      "    class 1       0.00      0.00      0.00       439\n",
      "\n",
      "avg / total       0.97      0.98      0.97     26005\n",
      "\n",
      "[[25566     0]\n",
      " [  439     0]]\n",
      "*********************************************************\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "def drange(start, stop, step):\n",
    "    while start < stop:\n",
    "            yield start\n",
    "            start += step\n",
    "\n",
    "\n",
    "for j in drange(0.00, 1.00, 0.01):\n",
    "    cutoff = j\n",
    "    y_pred = list()\n",
    "    for i in range(0,len(predicted[:,1])):\n",
    "        if predicted[:,1][i] > cutoff:\n",
    "            y_pred.append(1)\n",
    "        else:\n",
    "            y_pred.append(0)\n",
    "    target_names = ['class 0', 'class 1']\n",
    "    print \"Cutoff = {}\".format(cutoff)\n",
    "    print(classification_report(y_test, y_pred, target_names=target_names))\n",
    "    print confusion_matrix(y_test, y_pred)\n",
    "    print(\"*********************************************************\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 586,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import the train dataset\n",
    "data_test = pd.read_csv('test.csv')\n",
    "\n",
    "# Taking only the required attributes\n",
    "X_test = data_test.iloc[:,0:25]\n",
    "X_test = np.array(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 587,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predicted = model.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 588,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cutoff = 0.45\n",
    "y_pred = list()\n",
    "for i in range(0,len(predicted[:,1])):\n",
    "    if predicted[:,1][i] > cutoff:\n",
    "        y_pred.append(1)\n",
    "    else:\n",
    "        y_pred.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 589,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({'user_id': data_test['user_id'], 'prediction(adopter)':y_pred})\n",
    "submission = submission[['user_id', 'prediction(adopter)']]\n",
    "submission.to_csv(\"xgboost_22ndNov.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"font-family:Times New Roman;\">Ensemble Method</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "model1 = LogisticRegression(random_state = 9, C = 0.001 , n_jobs = -1, penalty = 'l1', class_weight = 'balanced', intercept_scaling  = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model2 = RandomForestClassifier(n_estimators = 100, max_depth = 10, max_features = 7, min_samples_split = 4, bootstrap = True, oob_score = True, n_jobs = -1, class_weight = 'balanced', random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "mingw_path = 'C:\\\\Program Files\\\\mingw-w64\\\\x86_64-6.2.0-posix-seh-rt_v5-rev1\\\\mingw64\\\\bin'\n",
    "os.environ['PATH'] = mingw_path + ';' + os.environ['PATH']\n",
    "import xgboost as xgb\n",
    "\n",
    "model3 = xgb.XGBClassifier(\n",
    " learning_rate =0.1,\n",
    " n_estimators=100,\n",
    " max_depth=2,\n",
    " min_child_weight=8,\n",
    " gamma=5,\n",
    " subsample=1,\n",
    " colsample_bytree=0.5,\n",
    " #reg_lambda = 0.2,\n",
    " reg_alpha=0.2,\n",
    " objective= 'binary:logistic',\n",
    " nthread=10,\n",
    " scale_pos_weight=1,\n",
    " seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier  #GBM algorithm\n",
    "model4 = GradientBoostingClassifier(loss = 'deviance', learning_rate=0.05, min_weight_fraction_leaf = 0.1, min_samples_split=2, n_estimators=80, max_depth=20, subsample=0.1,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "ensemble_classifier = VotingClassifier(estimators=[('lr', model1), ('rf', model2), ('xgb', model3), ('gbc', model4)],voting='hard')#, weights = [1,1,1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ensemble_classifier = ensemble_classifier.fit(smox, smoy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predicted = ensemble_classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.99      0.97      0.98     25566\n",
      "    class 1       0.09      0.17      0.12       439\n",
      "\n",
      "avg / total       0.97      0.96      0.96     26005\n",
      "\n",
      "[[24810   756]\n",
      " [  365    74]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "target_names = ['class 0', 'class 1']\n",
    "print(classification_report(y_test, predicted, target_names=target_names))\n",
    "print confusion_matrix(y_test, predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "def drange(start, stop, step):\n",
    "    while start < stop:\n",
    "            yield start\n",
    "            start += step\n",
    "\n",
    "\n",
    "for j in drange(0.00, 1.00, 0.01):\n",
    "    cutoff = j\n",
    "    y_pred = list()\n",
    "    for i in range(0,len(predicted[:,1])):\n",
    "        if predicted[:,1][i] > cutoff:\n",
    "            y_pred.append(1)\n",
    "        else:\n",
    "            y_pred.append(0)\n",
    "    target_names = ['class 0', 'class 1']\n",
    "    print \"Cutoff = {}\".format(cutoff)\n",
    "    print(classification_report(y_test, y_pred, target_names=target_names))\n",
    "    print confusion_matrix(y_test, y_pred)\n",
    "    print(\"*********************************************************\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "ensemble_classifier = VotingClassifier(estimators=[('lr', model1), ('rf', model2), ('xgb', model3), ('gbc', model4)],voting='soft', weights = [1,1,1,20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ensemble_classifier = ensemble_classifier.fit(X_train, y_train)\n",
    "predicted = ensemble_classifier.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cutoff = 0.0\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.00      0.00      0.00     25566\n",
      "    class 1       0.02      1.00      0.03       439\n",
      "\n",
      "avg / total       0.00      0.02      0.00     26005\n",
      "\n",
      "[[    0 25566]\n",
      " [    0   439]]\n",
      "*********************************************************\n",
      "Cutoff = 0.01\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       1.00      0.00      0.00     25566\n",
      "    class 1       0.02      1.00      0.03       439\n",
      "\n",
      "avg / total       0.98      0.02      0.00     26005\n",
      "\n",
      "[[    3 25563]\n",
      " [    0   439]]\n",
      "*********************************************************\n",
      "Cutoff = 0.02\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       1.00      0.21      0.35     25566\n",
      "    class 1       0.02      0.98      0.04       439\n",
      "\n",
      "avg / total       0.98      0.23      0.35     26005\n",
      "\n",
      "[[ 5496 20070]\n",
      " [    7   432]]\n",
      "*********************************************************\n",
      "Cutoff = 0.03\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       1.00      0.47      0.64     25566\n",
      "    class 1       0.03      0.92      0.06       439\n",
      "\n",
      "avg / total       0.98      0.48      0.63     26005\n",
      "\n",
      "[[11964 13602]\n",
      " [   34   405]]\n",
      "*********************************************************\n",
      "Cutoff = 0.04\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       1.00      0.60      0.75     25566\n",
      "    class 1       0.03      0.83      0.07       439\n",
      "\n",
      "avg / total       0.98      0.60      0.74     26005\n",
      "\n",
      "[[15321 10245]\n",
      " [   76   363]]\n",
      "*********************************************************\n",
      "Cutoff = 0.05\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.99      0.70      0.82     25566\n",
      "    class 1       0.04      0.74      0.08       439\n",
      "\n",
      "avg / total       0.98      0.70      0.81     26005\n",
      "\n",
      "[[17828  7738]\n",
      " [  115   324]]\n",
      "*********************************************************\n",
      "Cutoff = 0.06\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.99      0.77      0.87     25566\n",
      "    class 1       0.05      0.65      0.09       439\n",
      "\n",
      "avg / total       0.98      0.77      0.85     26005\n",
      "\n",
      "[[19722  5844]\n",
      " [  154   285]]\n",
      "*********************************************************\n",
      "Cutoff = 0.07\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.99      0.83      0.90     25566\n",
      "    class 1       0.05      0.58      0.10       439\n",
      "\n",
      "avg / total       0.98      0.82      0.89     26005\n",
      "\n",
      "[[21134  4432]\n",
      " [  186   253]]\n",
      "*********************************************************\n",
      "Cutoff = 0.08\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.99      0.87      0.93     25566\n",
      "    class 1       0.06      0.49      0.11       439\n",
      "\n",
      "avg / total       0.97      0.87      0.91     26005\n",
      "\n",
      "[[22292  3274]\n",
      " [  223   216]]\n",
      "*********************************************************\n",
      "Cutoff = 0.09\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.99      0.91      0.95     25566\n",
      "    class 1       0.07      0.39      0.11       439\n",
      "\n",
      "avg / total       0.97      0.90      0.93     26005\n",
      "\n",
      "[[23168  2398]\n",
      " [  268   171]]\n",
      "*********************************************************\n",
      "Cutoff = 0.1\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.99      0.93      0.96     25566\n",
      "    class 1       0.07      0.32      0.12       439\n",
      "\n",
      "avg / total       0.97      0.92      0.94     26005\n",
      "\n",
      "[[23824  1742]\n",
      " [  298   141]]\n",
      "*********************************************************\n",
      "Cutoff = 0.11\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.99      0.95      0.97     25566\n",
      "    class 1       0.08      0.25      0.12       439\n",
      "\n",
      "avg / total       0.97      0.94      0.95     26005\n",
      "\n",
      "[[24329  1237]\n",
      " [  328   111]]\n",
      "*********************************************************\n",
      "Cutoff = 0.12\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.99      0.97      0.98     25566\n",
      "    class 1       0.08      0.17      0.11       439\n",
      "\n",
      "avg / total       0.97      0.95      0.96     26005\n",
      "\n",
      "[[24704   862]\n",
      " [  364    75]]\n",
      "*********************************************************\n",
      "Cutoff = 0.13\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.99      0.98      0.98     25566\n",
      "    class 1       0.10      0.14      0.12       439\n",
      "\n",
      "avg / total       0.97      0.96      0.97     26005\n",
      "\n",
      "[[24984   582]\n",
      " [  376    63]]\n",
      "*********************************************************\n",
      "Cutoff = 0.14\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.98      0.99      0.99     25566\n",
      "    class 1       0.11      0.10      0.11       439\n",
      "\n",
      "avg / total       0.97      0.97      0.97     26005\n",
      "\n",
      "[[25198   368]\n",
      " [  393    46]]\n",
      "*********************************************************\n",
      "Cutoff = 0.15\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.98      0.99      0.99     25566\n",
      "    class 1       0.12      0.07      0.09       439\n",
      "\n",
      "avg / total       0.97      0.98      0.97     26005\n",
      "\n",
      "[[25333   233]\n",
      " [  407    32]]\n",
      "*********************************************************\n",
      "Cutoff = 0.16\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.98      0.99      0.99     25566\n",
      "    class 1       0.10      0.04      0.05       439\n",
      "\n",
      "avg / total       0.97      0.98      0.97     26005\n",
      "\n",
      "[[25427   139]\n",
      " [  423    16]]\n",
      "*********************************************************\n",
      "Cutoff = 0.17\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.98      1.00      0.99     25566\n",
      "    class 1       0.15      0.03      0.04       439\n",
      "\n",
      "avg / total       0.97      0.98      0.97     26005\n",
      "\n",
      "[[25503    63]\n",
      " [  428    11]]\n",
      "*********************************************************\n",
      "Cutoff = 0.18\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.98      1.00      0.99     25566\n",
      "    class 1       0.17      0.01      0.02       439\n",
      "\n",
      "avg / total       0.97      0.98      0.97     26005\n",
      "\n",
      "[[25541    25]\n",
      " [  434     5]]\n",
      "*********************************************************\n",
      "Cutoff = 0.19\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.98      1.00      0.99     25566\n",
      "    class 1       0.27      0.01      0.01       439\n",
      "\n",
      "avg / total       0.97      0.98      0.97     26005\n",
      "\n",
      "[[25558     8]\n",
      " [  436     3]]\n",
      "*********************************************************\n",
      "Cutoff = 0.2\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.98      1.00      0.99     25566\n",
      "    class 1       0.00      0.00      0.00       439\n",
      "\n",
      "avg / total       0.97      0.98      0.97     26005\n",
      "\n",
      "[[25565     1]\n",
      " [  439     0]]\n",
      "*********************************************************\n",
      "Cutoff = 0.21\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.98      1.00      0.99     25566\n",
      "    class 1       0.00      0.00      0.00       439\n",
      "\n",
      "avg / total       0.97      0.98      0.97     26005\n",
      "\n",
      "[[25566     0]\n",
      " [  439     0]]\n",
      "*********************************************************\n",
      "Cutoff = 0.22\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.98      1.00      0.99     25566\n",
      "    class 1       0.00      0.00      0.00       439\n",
      "\n",
      "avg / total       0.97      0.98      0.97     26005\n",
      "\n",
      "[[25566     0]\n",
      " [  439     0]]\n",
      "*********************************************************\n",
      "Cutoff = 0.23\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.98      1.00      0.99     25566\n",
      "    class 1       0.00      0.00      0.00       439\n",
      "\n",
      "avg / total       0.97      0.98      0.97     26005\n",
      "\n",
      "[[25566     0]\n",
      " [  439     0]]\n",
      "*********************************************************\n",
      "Cutoff = 0.24\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.98      1.00      0.99     25566\n",
      "    class 1       0.00      0.00      0.00       439\n",
      "\n",
      "avg / total       0.97      0.98      0.97     26005\n",
      "\n",
      "[[25566     0]\n",
      " [  439     0]]\n",
      "*********************************************************\n",
      "Cutoff = 0.25\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.98      1.00      0.99     25566\n",
      "    class 1       0.00      0.00      0.00       439\n",
      "\n",
      "avg / total       0.97      0.98      0.97     26005\n",
      "\n",
      "[[25566     0]\n",
      " [  439     0]]\n",
      "*********************************************************\n",
      "Cutoff = 0.26\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.98      1.00      0.99     25566\n",
      "    class 1       0.00      0.00      0.00       439\n",
      "\n",
      "avg / total       0.97      0.98      0.97     26005\n",
      "\n",
      "[[25566     0]\n",
      " [  439     0]]\n",
      "*********************************************************\n",
      "Cutoff = 0.27\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.98      1.00      0.99     25566\n",
      "    class 1       0.00      0.00      0.00       439\n",
      "\n",
      "avg / total       0.97      0.98      0.97     26005\n",
      "\n",
      "[[25566     0]\n",
      " [  439     0]]\n",
      "*********************************************************\n",
      "Cutoff = 0.28\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.98      1.00      0.99     25566\n",
      "    class 1       0.00      0.00      0.00       439\n",
      "\n",
      "avg / total       0.97      0.98      0.97     26005\n",
      "\n",
      "[[25566     0]\n",
      " [  439     0]]\n",
      "*********************************************************\n",
      "Cutoff = 0.29\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.98      1.00      0.99     25566\n",
      "    class 1       0.00      0.00      0.00       439\n",
      "\n",
      "avg / total       0.97      0.98      0.97     26005\n",
      "\n",
      "[[25566     0]\n",
      " [  439     0]]\n",
      "*********************************************************\n",
      "Cutoff = 0.3\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.98      1.00      0.99     25566\n",
      "    class 1       0.00      0.00      0.00       439\n",
      "\n",
      "avg / total       0.97      0.98      0.97     26005\n",
      "\n",
      "[[25566     0]\n",
      " [  439     0]]\n",
      "*********************************************************\n",
      "Cutoff = 0.31\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.98      1.00      0.99     25566\n",
      "    class 1       0.00      0.00      0.00       439\n",
      "\n",
      "avg / total       0.97      0.98      0.97     26005\n",
      "\n",
      "[[25566     0]\n",
      " [  439     0]]\n",
      "*********************************************************\n",
      "Cutoff = 0.32\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.98      1.00      0.99     25566\n",
      "    class 1       0.00      0.00      0.00       439\n",
      "\n",
      "avg / total       0.97      0.98      0.97     26005\n",
      "\n",
      "[[25566     0]\n",
      " [  439     0]]\n",
      "*********************************************************\n",
      "Cutoff = 0.33\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.98      1.00      0.99     25566\n",
      "    class 1       0.00      0.00      0.00       439\n",
      "\n",
      "avg / total       0.97      0.98      0.97     26005\n",
      "\n",
      "[[25566     0]\n",
      " [  439     0]]\n",
      "*********************************************************\n",
      "Cutoff = 0.34\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.98      1.00      0.99     25566\n",
      "    class 1       0.00      0.00      0.00       439\n",
      "\n",
      "avg / total       0.97      0.98      0.97     26005\n",
      "\n",
      "[[25566     0]\n",
      " [  439     0]]\n",
      "*********************************************************\n",
      "Cutoff = 0.35\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.98      1.00      0.99     25566\n",
      "    class 1       0.00      0.00      0.00       439\n",
      "\n",
      "avg / total       0.97      0.98      0.97     26005\n",
      "\n",
      "[[25566     0]\n",
      " [  439     0]]\n",
      "*********************************************************\n",
      "Cutoff = 0.36\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.98      1.00      0.99     25566\n",
      "    class 1       0.00      0.00      0.00       439\n",
      "\n",
      "avg / total       0.97      0.98      0.97     26005\n",
      "\n",
      "[[25566     0]\n",
      " [  439     0]]\n",
      "*********************************************************\n",
      "Cutoff = 0.37\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.98      1.00      0.99     25566\n",
      "    class 1       0.00      0.00      0.00       439\n",
      "\n",
      "avg / total       0.97      0.98      0.97     26005\n",
      "\n",
      "[[25566     0]\n",
      " [  439     0]]\n",
      "*********************************************************\n",
      "Cutoff = 0.38\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.98      1.00      0.99     25566\n",
      "    class 1       0.00      0.00      0.00       439\n",
      "\n",
      "avg / total       0.97      0.98      0.97     26005\n",
      "\n",
      "[[25566     0]\n",
      " [  439     0]]\n",
      "*********************************************************\n",
      "Cutoff = 0.39\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.98      1.00      0.99     25566\n",
      "    class 1       0.00      0.00      0.00       439\n",
      "\n",
      "avg / total       0.97      0.98      0.97     26005\n",
      "\n",
      "[[25566     0]\n",
      " [  439     0]]\n",
      "*********************************************************\n",
      "Cutoff = 0.4\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.98      1.00      0.99     25566\n",
      "    class 1       0.00      0.00      0.00       439\n",
      "\n",
      "avg / total       0.97      0.98      0.97     26005\n",
      "\n",
      "[[25566     0]\n",
      " [  439     0]]\n",
      "*********************************************************\n",
      "Cutoff = 0.41\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.98      1.00      0.99     25566\n",
      "    class 1       0.00      0.00      0.00       439\n",
      "\n",
      "avg / total       0.97      0.98      0.97     26005\n",
      "\n",
      "[[25566     0]\n",
      " [  439     0]]\n",
      "*********************************************************\n",
      "Cutoff = 0.42\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.98      1.00      0.99     25566\n",
      "    class 1       0.00      0.00      0.00       439\n",
      "\n",
      "avg / total       0.97      0.98      0.97     26005\n",
      "\n",
      "[[25566     0]\n",
      " [  439     0]]\n",
      "*********************************************************\n",
      "Cutoff = 0.43\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.98      1.00      0.99     25566\n",
      "    class 1       0.00      0.00      0.00       439\n",
      "\n",
      "avg / total       0.97      0.98      0.97     26005\n",
      "\n",
      "[[25566     0]\n",
      " [  439     0]]\n",
      "*********************************************************\n",
      "Cutoff = 0.44\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.98      1.00      0.99     25566\n",
      "    class 1       0.00      0.00      0.00       439\n",
      "\n",
      "avg / total       0.97      0.98      0.97     26005\n",
      "\n",
      "[[25566     0]\n",
      " [  439     0]]\n",
      "*********************************************************\n",
      "Cutoff = 0.45\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.98      1.00      0.99     25566\n",
      "    class 1       0.00      0.00      0.00       439\n",
      "\n",
      "avg / total       0.97      0.98      0.97     26005\n",
      "\n",
      "[[25566     0]\n",
      " [  439     0]]\n",
      "*********************************************************\n",
      "Cutoff = 0.46\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.98      1.00      0.99     25566\n",
      "    class 1       0.00      0.00      0.00       439\n",
      "\n",
      "avg / total       0.97      0.98      0.97     26005\n",
      "\n",
      "[[25566     0]\n",
      " [  439     0]]\n",
      "*********************************************************\n",
      "Cutoff = 0.47\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.98      1.00      0.99     25566\n",
      "    class 1       0.00      0.00      0.00       439\n",
      "\n",
      "avg / total       0.97      0.98      0.97     26005\n",
      "\n",
      "[[25566     0]\n",
      " [  439     0]]\n",
      "*********************************************************\n",
      "Cutoff = 0.48\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.98      1.00      0.99     25566\n",
      "    class 1       0.00      0.00      0.00       439\n",
      "\n",
      "avg / total       0.97      0.98      0.97     26005\n",
      "\n",
      "[[25566     0]\n",
      " [  439     0]]\n",
      "*********************************************************\n",
      "Cutoff = 0.49\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.98      1.00      0.99     25566\n",
      "    class 1       0.00      0.00      0.00       439\n",
      "\n",
      "avg / total       0.97      0.98      0.97     26005\n",
      "\n",
      "[[25566     0]\n",
      " [  439     0]]\n",
      "*********************************************************\n",
      "Cutoff = 0.5\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.98      1.00      0.99     25566\n",
      "    class 1       0.00      0.00      0.00       439\n",
      "\n",
      "avg / total       0.97      0.98      0.97     26005\n",
      "\n",
      "[[25566     0]\n",
      " [  439     0]]\n",
      "*********************************************************\n",
      "Cutoff = 0.51\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.98      1.00      0.99     25566\n",
      "    class 1       0.00      0.00      0.00       439\n",
      "\n",
      "avg / total       0.97      0.98      0.97     26005\n",
      "\n",
      "[[25566     0]\n",
      " [  439     0]]\n",
      "*********************************************************\n",
      "Cutoff = 0.52\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.98      1.00      0.99     25566\n",
      "    class 1       0.00      0.00      0.00       439\n",
      "\n",
      "avg / total       0.97      0.98      0.97     26005\n",
      "\n",
      "[[25566     0]\n",
      " [  439     0]]\n",
      "*********************************************************\n",
      "Cutoff = 0.53\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.98      1.00      0.99     25566\n",
      "    class 1       0.00      0.00      0.00       439\n",
      "\n",
      "avg / total       0.97      0.98      0.97     26005\n",
      "\n",
      "[[25566     0]\n",
      " [  439     0]]\n",
      "*********************************************************\n",
      "Cutoff = 0.54\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.98      1.00      0.99     25566\n",
      "    class 1       0.00      0.00      0.00       439\n",
      "\n",
      "avg / total       0.97      0.98      0.97     26005\n",
      "\n",
      "[[25566     0]\n",
      " [  439     0]]\n",
      "*********************************************************\n",
      "Cutoff = 0.55\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.98      1.00      0.99     25566\n",
      "    class 1       0.00      0.00      0.00       439\n",
      "\n",
      "avg / total       0.97      0.98      0.97     26005\n",
      "\n",
      "[[25566     0]\n",
      " [  439     0]]\n",
      "*********************************************************\n",
      "Cutoff = 0.56\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.98      1.00      0.99     25566\n",
      "    class 1       0.00      0.00      0.00       439\n",
      "\n",
      "avg / total       0.97      0.98      0.97     26005\n",
      "\n",
      "[[25566     0]\n",
      " [  439     0]]\n",
      "*********************************************************\n",
      "Cutoff = 0.57\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.98      1.00      0.99     25566\n",
      "    class 1       0.00      0.00      0.00       439\n",
      "\n",
      "avg / total       0.97      0.98      0.97     26005\n",
      "\n",
      "[[25566     0]\n",
      " [  439     0]]\n",
      "*********************************************************\n",
      "Cutoff = 0.58\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.98      1.00      0.99     25566\n",
      "    class 1       0.00      0.00      0.00       439\n",
      "\n",
      "avg / total       0.97      0.98      0.97     26005\n",
      "\n",
      "[[25566     0]\n",
      " [  439     0]]\n",
      "*********************************************************\n",
      "Cutoff = 0.59\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.98      1.00      0.99     25566\n",
      "    class 1       0.00      0.00      0.00       439\n",
      "\n",
      "avg / total       0.97      0.98      0.97     26005\n",
      "\n",
      "[[25566     0]\n",
      " [  439     0]]\n",
      "*********************************************************\n",
      "Cutoff = 0.6\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.98      1.00      0.99     25566\n",
      "    class 1       0.00      0.00      0.00       439\n",
      "\n",
      "avg / total       0.97      0.98      0.97     26005\n",
      "\n",
      "[[25566     0]\n",
      " [  439     0]]\n",
      "*********************************************************\n",
      "Cutoff = 0.61\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.98      1.00      0.99     25566\n",
      "    class 1       0.00      0.00      0.00       439\n",
      "\n",
      "avg / total       0.97      0.98      0.97     26005\n",
      "\n",
      "[[25566     0]\n",
      " [  439     0]]\n",
      "*********************************************************\n",
      "Cutoff = 0.62\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.98      1.00      0.99     25566\n",
      "    class 1       0.00      0.00      0.00       439\n",
      "\n",
      "avg / total       0.97      0.98      0.97     26005\n",
      "\n",
      "[[25566     0]\n",
      " [  439     0]]\n",
      "*********************************************************\n",
      "Cutoff = 0.63\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.98      1.00      0.99     25566\n",
      "    class 1       0.00      0.00      0.00       439\n",
      "\n",
      "avg / total       0.97      0.98      0.97     26005\n",
      "\n",
      "[[25566     0]\n",
      " [  439     0]]\n",
      "*********************************************************\n",
      "Cutoff = 0.64\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.98      1.00      0.99     25566\n",
      "    class 1       0.00      0.00      0.00       439\n",
      "\n",
      "avg / total       0.97      0.98      0.97     26005\n",
      "\n",
      "[[25566     0]\n",
      " [  439     0]]\n",
      "*********************************************************\n",
      "Cutoff = 0.65\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.98      1.00      0.99     25566\n",
      "    class 1       0.00      0.00      0.00       439\n",
      "\n",
      "avg / total       0.97      0.98      0.97     26005\n",
      "\n",
      "[[25566     0]\n",
      " [  439     0]]\n",
      "*********************************************************\n",
      "Cutoff = 0.66\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.98      1.00      0.99     25566\n",
      "    class 1       0.00      0.00      0.00       439\n",
      "\n",
      "avg / total       0.97      0.98      0.97     26005\n",
      "\n",
      "[[25566     0]\n",
      " [  439     0]]\n",
      "*********************************************************\n",
      "Cutoff = 0.67\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.98      1.00      0.99     25566\n",
      "    class 1       0.00      0.00      0.00       439\n",
      "\n",
      "avg / total       0.97      0.98      0.97     26005\n",
      "\n",
      "[[25566     0]\n",
      " [  439     0]]\n",
      "*********************************************************\n",
      "Cutoff = 0.68\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.98      1.00      0.99     25566\n",
      "    class 1       0.00      0.00      0.00       439\n",
      "\n",
      "avg / total       0.97      0.98      0.97     26005\n",
      "\n",
      "[[25566     0]\n",
      " [  439     0]]\n",
      "*********************************************************\n",
      "Cutoff = 0.69\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.98      1.00      0.99     25566\n",
      "    class 1       0.00      0.00      0.00       439\n",
      "\n",
      "avg / total       0.97      0.98      0.97     26005\n",
      "\n",
      "[[25566     0]\n",
      " [  439     0]]\n",
      "*********************************************************\n",
      "Cutoff = 0.7\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.98      1.00      0.99     25566\n",
      "    class 1       0.00      0.00      0.00       439\n",
      "\n",
      "avg / total       0.97      0.98      0.97     26005\n",
      "\n",
      "[[25566     0]\n",
      " [  439     0]]\n",
      "*********************************************************\n",
      "Cutoff = 0.71\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.98      1.00      0.99     25566\n",
      "    class 1       0.00      0.00      0.00       439\n",
      "\n",
      "avg / total       0.97      0.98      0.97     26005\n",
      "\n",
      "[[25566     0]\n",
      " [  439     0]]\n",
      "*********************************************************\n",
      "Cutoff = 0.72\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.98      1.00      0.99     25566\n",
      "    class 1       0.00      0.00      0.00       439\n",
      "\n",
      "avg / total       0.97      0.98      0.97     26005\n",
      "\n",
      "[[25566     0]\n",
      " [  439     0]]\n",
      "*********************************************************\n",
      "Cutoff = 0.73\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.98      1.00      0.99     25566\n",
      "    class 1       0.00      0.00      0.00       439\n",
      "\n",
      "avg / total       0.97      0.98      0.97     26005\n",
      "\n",
      "[[25566     0]\n",
      " [  439     0]]\n",
      "*********************************************************\n",
      "Cutoff = 0.74\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.98      1.00      0.99     25566\n",
      "    class 1       0.00      0.00      0.00       439\n",
      "\n",
      "avg / total       0.97      0.98      0.97     26005\n",
      "\n",
      "[[25566     0]\n",
      " [  439     0]]\n",
      "*********************************************************\n",
      "Cutoff = 0.75\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.98      1.00      0.99     25566\n",
      "    class 1       0.00      0.00      0.00       439\n",
      "\n",
      "avg / total       0.97      0.98      0.97     26005\n",
      "\n",
      "[[25566     0]\n",
      " [  439     0]]\n",
      "*********************************************************\n",
      "Cutoff = 0.76\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.98      1.00      0.99     25566\n",
      "    class 1       0.00      0.00      0.00       439\n",
      "\n",
      "avg / total       0.97      0.98      0.97     26005\n",
      "\n",
      "[[25566     0]\n",
      " [  439     0]]\n",
      "*********************************************************\n",
      "Cutoff = 0.77\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.98      1.00      0.99     25566\n",
      "    class 1       0.00      0.00      0.00       439\n",
      "\n",
      "avg / total       0.97      0.98      0.97     26005\n",
      "\n",
      "[[25566     0]\n",
      " [  439     0]]\n",
      "*********************************************************\n",
      "Cutoff = 0.78\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.98      1.00      0.99     25566\n",
      "    class 1       0.00      0.00      0.00       439\n",
      "\n",
      "avg / total       0.97      0.98      0.97     26005\n",
      "\n",
      "[[25566     0]\n",
      " [  439     0]]\n",
      "*********************************************************\n",
      "Cutoff = 0.79\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.98      1.00      0.99     25566\n",
      "    class 1       0.00      0.00      0.00       439\n",
      "\n",
      "avg / total       0.97      0.98      0.97     26005\n",
      "\n",
      "[[25566     0]\n",
      " [  439     0]]\n",
      "*********************************************************\n",
      "Cutoff = 0.8\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.98      1.00      0.99     25566\n",
      "    class 1       0.00      0.00      0.00       439\n",
      "\n",
      "avg / total       0.97      0.98      0.97     26005\n",
      "\n",
      "[[25566     0]\n",
      " [  439     0]]\n",
      "*********************************************************\n",
      "Cutoff = 0.81\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.98      1.00      0.99     25566\n",
      "    class 1       0.00      0.00      0.00       439\n",
      "\n",
      "avg / total       0.97      0.98      0.97     26005\n",
      "\n",
      "[[25566     0]\n",
      " [  439     0]]\n",
      "*********************************************************\n",
      "Cutoff = 0.82\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.98      1.00      0.99     25566\n",
      "    class 1       0.00      0.00      0.00       439\n",
      "\n",
      "avg / total       0.97      0.98      0.97     26005\n",
      "\n",
      "[[25566     0]\n",
      " [  439     0]]\n",
      "*********************************************************\n",
      "Cutoff = 0.83\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.98      1.00      0.99     25566\n",
      "    class 1       0.00      0.00      0.00       439\n",
      "\n",
      "avg / total       0.97      0.98      0.97     26005\n",
      "\n",
      "[[25566     0]\n",
      " [  439     0]]\n",
      "*********************************************************\n",
      "Cutoff = 0.84\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.98      1.00      0.99     25566\n",
      "    class 1       0.00      0.00      0.00       439\n",
      "\n",
      "avg / total       0.97      0.98      0.97     26005\n",
      "\n",
      "[[25566     0]\n",
      " [  439     0]]\n",
      "*********************************************************\n",
      "Cutoff = 0.85\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.98      1.00      0.99     25566\n",
      "    class 1       0.00      0.00      0.00       439\n",
      "\n",
      "avg / total       0.97      0.98      0.97     26005\n",
      "\n",
      "[[25566     0]\n",
      " [  439     0]]\n",
      "*********************************************************\n",
      "Cutoff = 0.86\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.98      1.00      0.99     25566\n",
      "    class 1       0.00      0.00      0.00       439\n",
      "\n",
      "avg / total       0.97      0.98      0.97     26005\n",
      "\n",
      "[[25566     0]\n",
      " [  439     0]]\n",
      "*********************************************************\n",
      "Cutoff = 0.87\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.98      1.00      0.99     25566\n",
      "    class 1       0.00      0.00      0.00       439\n",
      "\n",
      "avg / total       0.97      0.98      0.97     26005\n",
      "\n",
      "[[25566     0]\n",
      " [  439     0]]\n",
      "*********************************************************\n",
      "Cutoff = 0.88\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.98      1.00      0.99     25566\n",
      "    class 1       0.00      0.00      0.00       439\n",
      "\n",
      "avg / total       0.97      0.98      0.97     26005\n",
      "\n",
      "[[25566     0]\n",
      " [  439     0]]\n",
      "*********************************************************\n",
      "Cutoff = 0.89\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.98      1.00      0.99     25566\n",
      "    class 1       0.00      0.00      0.00       439\n",
      "\n",
      "avg / total       0.97      0.98      0.97     26005\n",
      "\n",
      "[[25566     0]\n",
      " [  439     0]]\n",
      "*********************************************************\n",
      "Cutoff = 0.9\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.98      1.00      0.99     25566\n",
      "    class 1       0.00      0.00      0.00       439\n",
      "\n",
      "avg / total       0.97      0.98      0.97     26005\n",
      "\n",
      "[[25566     0]\n",
      " [  439     0]]\n",
      "*********************************************************\n",
      "Cutoff = 0.91\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.98      1.00      0.99     25566\n",
      "    class 1       0.00      0.00      0.00       439\n",
      "\n",
      "avg / total       0.97      0.98      0.97     26005\n",
      "\n",
      "[[25566     0]\n",
      " [  439     0]]\n",
      "*********************************************************\n",
      "Cutoff = 0.92\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.98      1.00      0.99     25566\n",
      "    class 1       0.00      0.00      0.00       439\n",
      "\n",
      "avg / total       0.97      0.98      0.97     26005\n",
      "\n",
      "[[25566     0]\n",
      " [  439     0]]\n",
      "*********************************************************\n",
      "Cutoff = 0.93\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.98      1.00      0.99     25566\n",
      "    class 1       0.00      0.00      0.00       439\n",
      "\n",
      "avg / total       0.97      0.98      0.97     26005\n",
      "\n",
      "[[25566     0]\n",
      " [  439     0]]\n",
      "*********************************************************\n",
      "Cutoff = 0.94\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.98      1.00      0.99     25566\n",
      "    class 1       0.00      0.00      0.00       439\n",
      "\n",
      "avg / total       0.97      0.98      0.97     26005\n",
      "\n",
      "[[25566     0]\n",
      " [  439     0]]\n",
      "*********************************************************\n",
      "Cutoff = 0.95\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.98      1.00      0.99     25566\n",
      "    class 1       0.00      0.00      0.00       439\n",
      "\n",
      "avg / total       0.97      0.98      0.97     26005\n",
      "\n",
      "[[25566     0]\n",
      " [  439     0]]\n",
      "*********************************************************\n",
      "Cutoff = 0.96\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.98      1.00      0.99     25566\n",
      "    class 1       0.00      0.00      0.00       439\n",
      "\n",
      "avg / total       0.97      0.98      0.97     26005\n",
      "\n",
      "[[25566     0]\n",
      " [  439     0]]\n",
      "*********************************************************\n",
      "Cutoff = 0.97\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.98      1.00      0.99     25566\n",
      "    class 1       0.00      0.00      0.00       439\n",
      "\n",
      "avg / total       0.97      0.98      0.97     26005\n",
      "\n",
      "[[25566     0]\n",
      " [  439     0]]\n",
      "*********************************************************\n",
      "Cutoff = 0.98\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.98      1.00      0.99     25566\n",
      "    class 1       0.00      0.00      0.00       439\n",
      "\n",
      "avg / total       0.97      0.98      0.97     26005\n",
      "\n",
      "[[25566     0]\n",
      " [  439     0]]\n",
      "*********************************************************\n",
      "Cutoff = 0.99\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.98      1.00      0.99     25566\n",
      "    class 1       0.00      0.00      0.00       439\n",
      "\n",
      "avg / total       0.97      0.98      0.97     26005\n",
      "\n",
      "[[25566     0]\n",
      " [  439     0]]\n",
      "*********************************************************\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "def drange(start, stop, step):\n",
    "    while start < stop:\n",
    "            yield start\n",
    "            start += step\n",
    "\n",
    "\n",
    "for j in drange(0.00, 1.00, 0.01):\n",
    "    cutoff = j\n",
    "    y_pred = list()\n",
    "    for i in range(0,len(predicted[:,1])):\n",
    "        if predicted[:,1][i] > cutoff:\n",
    "            y_pred.append(1)\n",
    "        else:\n",
    "            y_pred.append(0)\n",
    "    target_names = ['class 0', 'class 1']\n",
    "    print \"Cutoff = {}\".format(cutoff)\n",
    "    print(classification_report(y_test, y_pred, target_names=target_names))\n",
    "    print confusion_matrix(y_test, y_pred)\n",
    "    print(\"*********************************************************\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
